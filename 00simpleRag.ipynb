{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and run a local RAG pipeline from scratch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is RAG ?\n",
    "\n",
    "RAG stands for retrieval augmented Generation.\n",
    "\n",
    "It was introduced in the paper [_Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks_](https://arxiv.org/abs/2005.11401).\n",
    "\n",
    "The goal of RAG is to take information and pass it to an LLM so it can generate outputs based on that information.\n",
    "\n",
    "- **Retrieval** --> Find Relevant information given a query , e.g. \"what are the macronutrients and what do they do?\" --> retrieves passages of the text related to the macronutrients from a nutrition textbook .\n",
    "\n",
    "- **Augmented** --> To take the relevant information and augment out input(prompt) to an LLm with that relevant information\n",
    "\n",
    "- **Generation**--> take result of above two steps and pass them on to a LLM for generative outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why RAG?\n",
    "\n",
    "The main goal of RAG is to improve the generation outputs of LLMs .\n",
    "\n",
    "1. To prevent hallucinations - LLMs are capable of generating _good looking_ texts , but that doesn't mean , it is factually correct , RAG can help LLMs to generate passage based on relevant passages that are factual .\n",
    "\n",
    "2. Work with Custom Data - Many base LLMs are trained with internet-scale data. This means they have a fairly good understanding of language in general , However that also means the responses can be generic in nature , RAG helps generating based on specific data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What can be RAG used for?\n",
    "\n",
    "- Customer Support QNA chat -- Treat your existing support docs as a resource and when a customer asks a question , you could have a retrieval system , retrieve relevant documentation snippets and then have an LLM craft those snippets into an answer .\n",
    "\n",
    "- Email chain analysis -- Lets say you're a large insurance company and you have chains and chais of emails of customer claims . You have use a RAG pipeline to find revelant information from those emailand then use an LLM to process them into structured data.\n",
    "\n",
    "- Company internal Documentation Chat\n",
    "\n",
    "- TextBook Q&A -- Lets say you are a student and you've got a 1200 page textbook read textbook , you could build a RAG pipeline to go through and find relevant passages to the questions you have..\n",
    "\n",
    "Common theme -- take your document to a query and process them with an LLM\n",
    "\n",
    "From this angle , you can consider an LLM as a calculator for words.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Local?\n",
    "\n",
    "Fun...\n",
    "\n",
    "Privacy , Speed and Cost\n",
    "\n",
    "- Privacy -- IF you have a private documentation, maybe you dont want to send you information to an API , You want to setup an LLM and run it on your own Hardware.\n",
    "\n",
    "- Speed -- Whenever you use an API , you have to send some kind of data across the internet which takes time. Running Locally means we dont have to wait for transfer of data\n",
    "\n",
    "- Cost -- If You own you own hardware , the cost is paid , no or least operational cost , only Initial cost.\n",
    "\n",
    "- no Vendor Lockin - if API shuts down , you dont have to worry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.backends.mps.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key terms\n",
    "\n",
    "| Term                                | Description                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |\n",
    "| ----------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **Token**                           | A sub-word piece of text. For example, \"hello, world!\" could be split into [\"hello\", \",\", \"world\", \"!\"]. A token can be a whole word,<br> part of a word or group of punctuation characters. 1 token ~= 4 characters in English, 100 tokens ~= 75 words.<br> Text gets broken into tokens before being passed to an LLM.                                                                                                                                                                                                                                                                                  |\n",
    "| **Embedding**                       | A learned numerical representation of a piece of data. For example, a sentence of text could be represented by a vector with<br> 768 values. Similar pieces of text (in meaning) will ideally have similar values.                                                                                                                                                                                                                                                                                                                                                                                        |\n",
    "| **Embedding model**                 | A model designed to accept input data and output a numerical representation. For example, a text embedding model may take in 384 <br>tokens of text and turn it into a vector of size 768. An embedding model can and often is different to an LLM model.                                                                                                                                                                                                                                                                                                                                                 |\n",
    "| **Similarity search/vector search** | Similarity search/vector search aims to find two vectors which are close together in high-demensional space. For example, <br>two pieces of similar text passed through an embedding model should have a high similarity score, whereas two pieces of text about<br> different topics will have a lower similarity score. Common similarity score measures are dot product and cosine similarity.                                                                                                                                                                                                         |\n",
    "| **Large Language Model (LLM)**      | A model which has been trained to numerically represent the patterns in text. A generative LLM will continue a sequence when given a sequence. <br>For example, given a sequence of the text \"hello, world!\", a genertive LLM may produce \"we're going to build a RAG pipeline today!\".<br> This generation will be highly dependant on the training data and prompt.                                                                                                                                                                                                                                     |\n",
    "| **LLM context window**              | The number of tokens a LLM can accept as input. For example, as of March 2024, GPT-4 has a default context window of 32k tokens<br> (about 96 pages of text) but can go up to 128k if needed. A recent open-source LLM from Google, Gemma (March 2024) has a context<br> window of 8,192 tokens (about 24 pages of text). A higher context window means an LLM can accept more relevant information<br> to assist with a query. For example, in a RAG pipeline, if a model has a larger context window, it can accept more reference items<br> from the retrieval system to aid with its generation.      |\n",
    "| **Prompt**                          | A common term for describing the input to a generative LLM. The idea of \"[prompt engineering](https://en.wikipedia.org/wiki/Prompt_engineering)\" is to structure a text-based<br> (or potentially image-based as well) input to a generative LLM in a specific way so that the generated output is ideal. This technique is<br> possible because of a LLMs capacity for in-context learning, as in, it is able to use its representation of language to breakdown <br>the prompt and recognize what a suitable output may be (note: the output of LLMs is probable, so terms like \"may output\" are used). |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What we're going to build\n",
    "\n",
    "We're going to build RAG pipeline which enables us to chat with a PDF document, specifically an open-source [nutrition textbook](https://pressbooks.oer.hawaii.edu/humannutrition2/), ~1200 pages long.\n",
    "\n",
    "You could call our project NutriChat!\n",
    "\n",
    "We'll write the code to:\n",
    "\n",
    "1. Open a PDF document (you could use almost any PDF here).\n",
    "2. Format the text of the PDF textbook ready for an embedding model (this process is known as text splitting/chunking).\n",
    "3. Embed all of the chunks of text in the textbook and turn them into numerical representation which we can store for later.\n",
    "4. Build a retrieval system that uses vector search to find relevant chunks of text based on a query.\n",
    "5. Create a prompt that incorporates the retrieved pieces of text.\n",
    "6. Generate an answer to a query based on passages from the textbook.\n",
    "\n",
    "The above steps can broken down into two major sections:\n",
    "\n",
    "1. Document preprocessing/embedding creation (steps 1-3).\n",
    "2. Search and answer (steps 4-6).\n",
    "\n",
    "And that's the structure we'll follow.\n",
    "\n",
    "It's similar to the workflow outlined on the NVIDIA blog which [details a local RAG pipeline](https://developer.nvidia.com/blog/rag-101-demystifying-retrieval-augmented-generation-pipelines/).\n",
    "\n",
    "<img src=\"https://github.com/mrdbourke/simple-local-rag/blob/main/images/simple-local-rag-workflow-flowchart.png?raw=true\" alt=\"flowchart of a local RAG workflow\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Document/Text Processing and Embedding Creation\n",
    "\n",
    "Ingredients:\n",
    "\n",
    "- PDF document of choice.\n",
    "- Embedding model of choice.\n",
    "\n",
    "Steps:\n",
    "\n",
    "1. Import PDF document.\n",
    "2. Process text for embedding (e.g. split into chunks of sentences).\n",
    "3. Embed text chunks with embedding model.\n",
    "4. Save embeddings to file for later use (embeddings will store on file for many years or until you lose your hard drive).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import PDF Document\n",
    "\n",
    "This will work with many other kinds of documents.\n",
    "\n",
    "However, we'll start with PDF since many people have PDFs.\n",
    "\n",
    "But just keep in mind, text files, email chains, support documentation, articles and more can also work.\n",
    "\n",
    "We're going to pretend we're nutrition students at the University of Hawai'i, reading through the open-source PDF textbook [_Human Nutrition: 2020 Edition_](https://pressbooks.oer.hawaii.edu/humannutrition2/).\n",
    "\n",
    "There are several libraries to open PDFs with Python but I found that [PyMuPDF](https://github.com/pymupdf/pymupdf) works quite well in many cases.\n",
    "\n",
    "First we'll download the PDF if it doesn't exist.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File human-nutrition-text.pdf exists.\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import requests\n",
    "\n",
    "#Get pdf path\n",
    "pdf_path = \"human-nutrition-text.pdf\"\n",
    "\n",
    "#download pdf if it does not exist \n",
    "\n",
    "if not os.path.exists(pdf_path):\n",
    "    print(f\"[INFO] files doesn't exist , downloading...\")\n",
    "\n",
    "    # The URL of the PDF you want to download\n",
    "    url = \"https://pressbooks.oer.hawaii.edu/humannutrition2/open/download?type=pdf\"\n",
    "\n",
    "    # The local filename to save the downloaded file\n",
    "    filename = pdf_path\n",
    "\n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Open a file in binary write mode and save the content to it\n",
    "        with open(filename, \"wb\") as file:\n",
    "            file.write(response.content)\n",
    "        print(f\"The file has been downloaded and saved as {filename}\")\n",
    "    else:\n",
    "        print(f\"Failed to download the file. Status code: {response.status_code}\")\n",
    "else:\n",
    "    print(f\"File {pdf_path} exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PDF acquired!\n",
    "\n",
    "We can import the pages of our PDF to text by first defining the PDF path and then opening and reading it with PyMuPDF (`import fitz`).\n",
    "\n",
    "We'll write a small helper function to preprocess the text as it gets read. Note that not all text will be read in the same so keep this in mind for when you prepare your text.\n",
    "\n",
    "We'll save each page to a dictionary and then append that dictionary to a list for ease of use later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/swayamsingal/miniconda3/envs/research_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\n",
      "208it [00:01, 702.13it/s]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'page_number': -41,\n",
       "  'page_char_count': 29,\n",
       "  'page_word_count': 4,\n",
       "  'page_sentence_count_row': 1,\n",
       "  'page_token_count': 7.25,\n",
       "  'text': 'Human Nutrition: 2020 Edition'},\n",
       " {'page_number': -40,\n",
       "  'page_char_count': 0,\n",
       "  'page_word_count': 1,\n",
       "  'page_sentence_count_row': 1,\n",
       "  'page_token_count': 0.0,\n",
       "  'text': ''}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fitz\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def text_formatter(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Performs minor formatting on texts.\n",
    "    \"\"\"\n",
    "    cleaned_text = text.replace('\\n', \" \" ).strip()\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "def open_and_read_pdf(pdf_path : str)-> list[dict]:\n",
    "    doc = fitz.open(pdf_path)\n",
    "    pages_and_text = []\n",
    "    for page_number , page in tqdm(enumerate(doc)):\n",
    "        text = page.get_text()\n",
    "        text = text_formatter(text = text)\n",
    "        pages_and_text.append({\n",
    "            \"page_number\": page_number -41,\n",
    "            \"page_char_count\": len(text),\n",
    "            \"page_word_count\": len(text.split(\" \")),\n",
    "            \"page_sentence_count_row\": len(text.split(\". \")),\n",
    "            \"page_token_count\": len(text)/4,\n",
    "            \"text\":text\n",
    "            })\n",
    "    return pages_and_text\n",
    "\n",
    "pages_and_text = open_and_read_pdf(pdf_path = pdf_path)\n",
    "pages_and_text[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': 524,\n",
       "  'page_char_count': 1944,\n",
       "  'page_word_count': 321,\n",
       "  'page_sentence_count_row': 16,\n",
       "  'page_token_count': 486.0,\n",
       "  'text': 'The common occurrence of advanced xerophthalmia in children  who died from infectious diseases led scientists to hypothesize that  supplementing vitamin A in the diet for children with xerophthalmia  might reduce disease-related mortality. In Asia in the late 1980s,  targeted populations of children were administered vitamin A  supplements, and the death rates from measles and diarrhea  declined by up to 50 percent. Vitamin A supplementation in these  deficient populations did not reduce the number of children who  contracted these diseases, but it did decrease the severity of the  diseases so that they were no longer fatal. Soon after the results  of these studies were communicated to the rest of the world, the  World Health Organization (WHO) and the United Nations  Children’s Fund (UNICEF) commenced worldwide campaigns  against vitamin A deficiency. UNICEF estimates that the distribution  of over half a billion vitamin A capsules prevents 350,000 childhood  deaths annually.1  In the twenty-first century, science has demonstrated that  vitamin A greatly affects the immune system. What we are still  lacking are clinical trials investigating the proper doses of vitamin  A required to help ward off infectious disease and how large of  an effect vitamin A supplementation has on populations that are  not deficient in this vitamin. This brings up one of our common  themes in this text—micronutrient deficiencies may contribute to  the development, progression, and severity of a disease, but this  does not mean that an increased intake of these micronutrients will  solely prevent or cure disease. The effect, as usual, is cumulative and  depends on the diet as a whole, among other things.  1. Sommer A. (2008). Vitamin A Deficiency and Clinical  Disease: An Historical Overview. Journal of Nutrition, 138,  1835–39. http://jn.nutrition.org/content/138/10/ 1835.long. Accessed October 4, 2017.  524  |  Fat-Soluble Vitamins'},\n",
       " {'page_number': 826,\n",
       "  'page_char_count': 854,\n",
       "  'page_word_count': 145,\n",
       "  'page_sentence_count_row': 9,\n",
       "  'page_token_count': 213.5,\n",
       "  'text': 'Magnesium (mg)  310.0  350.0  310.0  Niacin (B3) (mg)  14.0  18.0  17.0  Phosphorus  700.0  700.0  700.0  Riboflavin (B2) (mg)  1.1  1.4  1.6  Thiamine (B1) (mg)  1.1  1.4  1.4  Zinc (mg)  8.0  11.0  12.0  Source: Institute of Medicine (2006). Dietary reference intakes: The  essential guide to nutrient requirements. The National Academies  Press.  https://www.nap.edu/catalog/11537/dietary-reference- intakes-the-essential-guide-to-nutrient-requirements  Calcium requirements do not change during breastfeeding because  of more efficient absorption, which is the case during pregnancy,  too. However, the reasons for this differ. During pregnancy, there  is enhanced absorption within the gastrointestinal tract. During  lactation, there is enhanced retention by the kidneys. The RDA for  phosphorus and fluoride also remains the same.  826  |  Infancy'},\n",
       " {'page_number': 119,\n",
       "  'page_char_count': 200,\n",
       "  'page_word_count': 35,\n",
       "  'page_sentence_count_row': 2,\n",
       "  'page_token_count': 50.0,\n",
       "  'text': 'An interactive or media element has been  excluded from this version of the text. You can  view it online here:  http://pressbooks.oer.hawaii.edu/ humannutrition2/?p=111    The Muscular System  |  119'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random \n",
    "\n",
    "random.sample(pages_and_text , k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count_row</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-41</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7.25</td>\n",
       "      <td>Human Nutrition: 2020 Edition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-39</td>\n",
       "      <td>320</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>80.00</td>\n",
       "      <td>Human Nutrition: 2020  Edition  UNIVERSITY OF ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-38</td>\n",
       "      <td>212</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>53.00</td>\n",
       "      <td>Human Nutrition: 2020 Edition by University of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-37</td>\n",
       "      <td>797</td>\n",
       "      <td>147</td>\n",
       "      <td>3</td>\n",
       "      <td>199.25</td>\n",
       "      <td>Contents  Preface  University of Hawai‘i at Mā...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_number  page_char_count  page_word_count  page_sentence_count_row  \\\n",
       "0          -41               29                4                        1   \n",
       "1          -40                0                1                        1   \n",
       "2          -39              320               54                        1   \n",
       "3          -38              212               32                        1   \n",
       "4          -37              797              147                        3   \n",
       "\n",
       "   page_token_count                                               text  \n",
       "0              7.25                      Human Nutrition: 2020 Edition  \n",
       "1              0.00                                                     \n",
       "2             80.00  Human Nutrition: 2020  Edition  UNIVERSITY OF ...  \n",
       "3             53.00  Human Nutrition: 2020 Edition by University of...  \n",
       "4            199.25  Contents  Preface  University of Hawai‘i at Mā...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df= pd.DataFrame(pages_and_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get some stats on the text\n",
    "\n",
    "Let's perform a rough exploratory data analysis (EDA) to get an idea of the size of the texts (e.g. character counts, word counts etc) we're working with.\n",
    "\n",
    "The different sizes of texts will be a good indicator into how we should split our texts.\n",
    "\n",
    "Many embedding models have limits on the size of texts they can ingest, for example, the [`sentence-transformers`](https://www.sbert.net/docs/pretrained_models.html) model [`all-mpnet-base-v2`](https://huggingface.co/sentence-transformers/all-mpnet-base-v2) has an input size of 384 tokens.\n",
    "\n",
    "This means that the model has been trained in ingest and turn into embeddings texts with 384 tokens (1 token ~= 4 characters ~= 0.75 words).\n",
    "\n",
    "Texts over 384 tokens which are encoded by this model will be auotmatically reduced to 384 tokens in length, potentially losing some information.\n",
    "\n",
    "We'll discuss this more in the embedding section.\n",
    "\n",
    "For now, let's turn our list of dictionaries into a DataFrame and explore it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count_row</th>\n",
       "      <th>page_token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>562.50</td>\n",
       "      <td>1148.00</td>\n",
       "      <td>199.50</td>\n",
       "      <td>10.52</td>\n",
       "      <td>287.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>348.86</td>\n",
       "      <td>560.38</td>\n",
       "      <td>95.83</td>\n",
       "      <td>6.55</td>\n",
       "      <td>140.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-41.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>260.75</td>\n",
       "      <td>762.00</td>\n",
       "      <td>134.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>190.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>562.50</td>\n",
       "      <td>1231.50</td>\n",
       "      <td>216.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>307.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>864.25</td>\n",
       "      <td>1603.50</td>\n",
       "      <td>272.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>400.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1166.00</td>\n",
       "      <td>2308.00</td>\n",
       "      <td>430.00</td>\n",
       "      <td>39.00</td>\n",
       "      <td>577.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  page_char_count  page_word_count  page_sentence_count_row  \\\n",
       "count      1208.00          1208.00          1208.00                  1208.00   \n",
       "mean        562.50          1148.00           199.50                    10.52   \n",
       "std         348.86           560.38            95.83                     6.55   \n",
       "min         -41.00             0.00             1.00                     1.00   \n",
       "25%         260.75           762.00           134.00                     5.00   \n",
       "50%         562.50          1231.50           216.00                    10.00   \n",
       "75%         864.25          1603.50           272.00                    15.00   \n",
       "max        1166.00          2308.00           430.00                    39.00   \n",
       "\n",
       "       page_token_count  \n",
       "count           1208.00  \n",
       "mean             287.00  \n",
       "std              140.10  \n",
       "min                0.00  \n",
       "25%              190.50  \n",
       "50%              307.88  \n",
       "75%              400.88  \n",
       "max              577.00  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, looks like our average token count per page is 287.\n",
    "\n",
    "For this particular use case, it means we could embed an average whole page with the `all-mpnet-base-v2` model (this model has an input capacity of 384).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further text processing (splitting pages into sentences)\n",
    "\n",
    "The ideal way of processing text before embedding it is still an active area of research.\n",
    "\n",
    "A simple method I've found helpful is to break the text into chunks of sentences.\n",
    "\n",
    "As in, chunk a page of text into groups of 5, 7, 10 or more sentences (these values are not set in stone and can be explored).\n",
    "\n",
    "But we want to follow the workflow of:\n",
    "\n",
    "`Ingest text -> split it into groups/chunks -> embed the groups/chunks -> use the embeddings`\n",
    "\n",
    "Some options for splitting text into sentences:\n",
    "\n",
    "1. Split into sentences with simple rules (e.g. split on \". \" with `text = text.split(\". \")`, like we did above).\n",
    "2. Split into sentences with a natural language processing (NLP) library such as [spaCy](https://spacy.io/) or [nltk](https://www.nltk.org/).\n",
    "\n",
    "Why split into sentences?\n",
    "\n",
    "- Easier to handle than larger pages of text (especially if pages are densely filled with text).\n",
    "- Can get specific and find out which group of sentences were used to help within a RAG pipeline.\n",
    "\n",
    "> **Resource:** See [spaCy install instructions](https://spacy.io/usage).\n",
    "\n",
    "Let's use spaCy to break our text into sentences since it's likely a bit more robust than just using `text.split(\". \")`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[This is a sentence., This another sentence., I like elephants]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy.lang.en import English\n",
    "\n",
    "nlp = English()\n",
    "\n",
    "# Add a sentencizer pipeline\n",
    "nlp.add_pipe(\"sentencizer\")\n",
    "\n",
    "# Create document instance as an example \n",
    "doc = nlp(\"This is a sentence. This another sentence. I like elephants\")\n",
    "assert len(list(doc.sents)) == 3\n",
    "\n",
    "list(doc.sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "00%|██████████████████████████████████████| 1208/1208 [00:01<00:00, 726.77it/s]"
     ]
    }
   ],
   "source": [
    "for item in tqdm(pages_and_text):\n",
    "    item[\"sentences\"] = list(nlp(item[\"text\"]).sents)\n",
    "    \n",
    "    #Make sure all sentences are strings\n",
    "    \n",
    "    item[\"sentences\"] = [str(sentence) for sentence in item[\"sentences\"]]\n",
    "    \n",
    "    #count the sentences\n",
    "    item[\"page_sentence_count_spacy\"] = len(item[\"sentences\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': 388,\n",
       "  'page_char_count': 1587,\n",
       "  'page_word_count': 272,\n",
       "  'page_sentence_count_row': 14,\n",
       "  'page_token_count': 396.75,\n",
       "  'text': 'Even a slight change in blood pH can affect body functions. Recall  that acidic conditions can cause protein denaturation, which stops  proteins from functioning. The body has several systems that hold  the blood pH within the normal range to prevent this from  happening. One of these is the circulating albumin. Albumin is  slightly acidic, and because it is negatively charged it balances the  many positively charged molecules, such as protons (H+), calcium,  potassium, and magnesium which are also circulating in the blood.  Albumin acts as a buffer against abrupt changes in the  concentrations of these molecules, thereby balancing blood pH and  maintaining the status quo. The protein hemoglobin also  participates in acid-base balance by binding and releasing protons.  Transport  Albumin and hemoglobin also play a role in molecular transport.  Albumin chemically binds to hormones, fatty acids, some vitamins,  essential minerals, and drugs, and transports them throughout the  circulatory system. Each red blood cell contains millions of  hemoglobin molecules that bind oxygen in the lungs and transport it  to all the tissues in the body. A cell’s plasma membrane is usually not  permeable to large polar molecules, so to get the required nutrients  and molecules into the cell many transport proteins exist in the  cell membrane. Some of these proteins are channels that allow  particular molecules to move in and out of cells. Others act as one- way taxis and require energy to function.  Protection  Figure 6.12 Antibody Proteins  388  |  Protein’s Functions in the Body',\n",
       "  'sentences': ['Even a slight change in blood pH can affect body functions.',\n",
       "   'Recall  that acidic conditions can cause protein denaturation, which stops  proteins from functioning.',\n",
       "   'The body has several systems that hold  the blood pH within the normal range to prevent this from  happening.',\n",
       "   'One of these is the circulating albumin.',\n",
       "   'Albumin is  slightly acidic, and because it is negatively charged it balances the  many positively charged molecules, such as protons (H+), calcium,  potassium, and magnesium which are also circulating in the blood.',\n",
       "   ' Albumin acts as a buffer against abrupt changes in the  concentrations of these molecules, thereby balancing blood pH and  maintaining the status quo.',\n",
       "   'The protein hemoglobin also  participates in acid-base balance by binding and releasing protons.',\n",
       "   ' Transport  Albumin and hemoglobin also play a role in molecular transport.',\n",
       "   ' Albumin chemically binds to hormones, fatty acids, some vitamins,  essential minerals, and drugs, and transports them throughout the  circulatory system.',\n",
       "   'Each red blood cell contains millions of  hemoglobin molecules that bind oxygen in the lungs and transport it  to all the tissues in the body.',\n",
       "   'A cell’s plasma membrane is usually not  permeable to large polar molecules, so to get the required nutrients  and molecules into the cell many transport proteins exist in the  cell membrane.',\n",
       "   'Some of these proteins are channels that allow  particular molecules to move in and out of cells.',\n",
       "   'Others act as one- way taxis and require energy to function.',\n",
       "   ' Protection  Figure 6.12 Antibody Proteins  388  |  Protein’s Functions in the Body'],\n",
       "  'page_sentence_count_spacy': 14}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(pages_and_text , k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count_row</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>page_sentence_count_spacy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>562.50</td>\n",
       "      <td>1148.00</td>\n",
       "      <td>199.50</td>\n",
       "      <td>10.52</td>\n",
       "      <td>287.00</td>\n",
       "      <td>10.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>348.86</td>\n",
       "      <td>560.38</td>\n",
       "      <td>95.83</td>\n",
       "      <td>6.55</td>\n",
       "      <td>140.10</td>\n",
       "      <td>6.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-41.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>260.75</td>\n",
       "      <td>762.00</td>\n",
       "      <td>134.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>190.50</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>562.50</td>\n",
       "      <td>1231.50</td>\n",
       "      <td>216.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>307.88</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>864.25</td>\n",
       "      <td>1603.50</td>\n",
       "      <td>272.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>400.88</td>\n",
       "      <td>15.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1166.00</td>\n",
       "      <td>2308.00</td>\n",
       "      <td>430.00</td>\n",
       "      <td>39.00</td>\n",
       "      <td>577.00</td>\n",
       "      <td>28.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  page_char_count  page_word_count  page_sentence_count_row  \\\n",
       "count      1208.00          1208.00          1208.00                  1208.00   \n",
       "mean        562.50          1148.00           199.50                    10.52   \n",
       "std         348.86           560.38            95.83                     6.55   \n",
       "min         -41.00             0.00             1.00                     1.00   \n",
       "25%         260.75           762.00           134.00                     5.00   \n",
       "50%         562.50          1231.50           216.00                    10.00   \n",
       "75%         864.25          1603.50           272.00                    15.00   \n",
       "max        1166.00          2308.00           430.00                    39.00   \n",
       "\n",
       "       page_token_count  page_sentence_count_spacy  \n",
       "count           1208.00                    1208.00  \n",
       "mean             287.00                      10.32  \n",
       "std              140.10                       6.30  \n",
       "min                0.00                       0.00  \n",
       "25%              190.50                       5.00  \n",
       "50%              307.88                      10.00  \n",
       "75%              400.88                      15.00  \n",
       "max              577.00                      28.00  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(pages_and_text)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunking our sentences together\n",
    "\n",
    "Let's take a step to break down our list of sentences/text into smaller chunks.\n",
    "\n",
    "As you might've guessed, this process is referred to as **chunking**.\n",
    "\n",
    "Why do we do this?\n",
    "\n",
    "1. Easier to manage similar sized chunks of text.\n",
    "2. Don't overload the embedding models capacity for tokens (e.g. if an embedding model has a capacity of 384 tokens, there could be information loss if you try to embed a sequence of 400+ tokens).\n",
    "3. Our LLM context window (the amount of tokens an LLM can take in) may be limited and requires compute power so we want to make sure we're using it as well as possible.\n",
    "\n",
    "Something to note is that there are many different ways emerging for creating chunks of information/text.\n",
    "\n",
    "For now, we're going to keep it simple and break our pages of sentences into groups of 10 (this number is arbitrary and can be changed, I just picked it because it seemed to line up well with our embedding model capacity of 384).\n",
    "\n",
    "On average each of our pages has 10 sentences.\n",
    "\n",
    "And an average total of 287 tokens per page.\n",
    "\n",
    "So our groups of 10 sentences will also be ~287 tokens long.\n",
    "\n",
    "This gives us plenty of room for the text to embedded by our `all-mpnet-base-v2` model (it has a capacity of 384 tokens).\n",
    "\n",
    "To split our groups of sentences into chunks of 10 or less, let's create a function which accepts a list as input and recursively breaks into down into sublists of a specified size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       " [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
       " [20, 21, 22, 23, 24]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define split size to turn groups of sentences into chunks\n",
    "\n",
    "num_sentences_chunk_size = 10\n",
    "\n",
    "#Create a function to split the list of text recursively into chunk size\n",
    "\n",
    "def split_list(input_list :list,\n",
    "               split_size:int = num_sentences_chunk_size) -> list[list[str]]:\n",
    "    return [input_list[i:i+split_size] for i in range(0, len(input_list), split_size)]\n",
    "\n",
    "test_list = list(range(25))\n",
    "split_list(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "00%|███████████████████████████████████| 1208/1208 [00:00<00:00, 188929.79it/s]"
     ]
    }
   ],
   "source": [
    "# loop through pages and texts and plit sentences into chunks\n",
    "\n",
    "for item in tqdm(pages_and_text):\n",
    "    item[\"sentence_chunks\"] = split_list(input_list=item[\"sentences\"])\n",
    "    \n",
    "    item[\"num_chunks\"] = len(item[\"sentence_chunks\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': 509,\n",
       "  'page_char_count': 1815,\n",
       "  'page_word_count': 284,\n",
       "  'page_sentence_count_row': 20,\n",
       "  'page_token_count': 453.75,\n",
       "  'text': 'overweight children.11 The results of this study were that a higher  percentage of children who made the small changes maintained or  reduced their BMI in comparison to children of families given a  pedometer but not asked to also make physical activity or dietary  changes.12 Several more studies funded by the National Institutes of  Health and USDA are ongoing and are evaluating the effectiveness  of the “small-changes” approach in reducing weight gain.  In 2009, a report of the Joint Task Force of the American Society  for Nutrition, Institute of Food Technologists, and International  Food Information Council proposed that the “small-changes”  approach when supported at the community, industry, and  governmental levels will be more effective than current strategies in  gradually reducing the obesity rate in America.13  11. Rodearmel SJ, Wyatt HR, et al. (2007). Small Changes in  Dietary Sugar and Physical Activity As an Approach to  Preventing Excessive Weight Gain: The America on the  Move Family Study. Pediatrics, 120(4), e869–79.  http://pediatrics.aappublications.org/content/120/4/ e869.long. Accessed September 22, 2017.  12. Rodearmel SJ, Wyatt HR, et al. (2007). Small Changes in  Dietary Sugar and Physical Activity As an Approach to  Preventing Excessive Weight Gain: The America on the  Move Family Study. Pediatrics, 120(4), e869–79.  http://pediatrics.aappublications.org/content/120/4/ e869.long. Accessed September 22, 2017.  13. Hill JO. (2009). Can a Small-Changes Approach Help  Address the Obesity Epidemic? A Report of the Joint  Task Force of the American Society for Nutrition,  Institute of Food Technologists, and International Food  Information Council. American Journal of Clinical  Dietary, Behavioral, and Physical Activity Recommendations for Weight Management  |  509',\n",
       "  'sentences': ['overweight children.11 The results of this study were that a higher  percentage of children who made the small changes maintained or  reduced their BMI in comparison to children of families given a  pedometer but not asked to also make physical activity or dietary  changes.12 Several more studies funded by the National Institutes of  Health and USDA are ongoing and are evaluating the effectiveness  of the “small-changes” approach in reducing weight gain.',\n",
       "   ' In 2009, a report of the Joint Task Force of the American Society  for Nutrition, Institute of Food Technologists, and International  Food Information Council proposed that the “small-changes”  approach when supported at the community, industry, and  governmental levels will be more effective than current strategies in  gradually reducing the obesity rate in America.13  11.',\n",
       "   'Rodearmel SJ, Wyatt HR, et al. (',\n",
       "   '2007).',\n",
       "   'Small Changes in  Dietary Sugar and Physical Activity As an Approach to  Preventing Excessive Weight Gain: The America on the  Move Family Study.',\n",
       "   'Pediatrics, 120(4), e869–79.',\n",
       "   ' http://pediatrics.aappublications.org/content/120/4/ e869.long.',\n",
       "   'Accessed September 22, 2017.',\n",
       "   ' 12.',\n",
       "   'Rodearmel SJ, Wyatt HR, et al. (',\n",
       "   '2007).',\n",
       "   'Small Changes in  Dietary Sugar and Physical Activity As an Approach to  Preventing Excessive Weight Gain: The America on the  Move Family Study.',\n",
       "   'Pediatrics, 120(4), e869–79.',\n",
       "   ' http://pediatrics.aappublications.org/content/120/4/ e869.long.',\n",
       "   'Accessed September 22, 2017.',\n",
       "   ' 13.',\n",
       "   'Hill JO. (',\n",
       "   '2009).',\n",
       "   'Can a Small-Changes Approach Help  Address the Obesity Epidemic?',\n",
       "   'A Report of the Joint  Task Force of the American Society for Nutrition,  Institute of Food Technologists, and International Food  Information Council.',\n",
       "   'American Journal of Clinical  Dietary, Behavioral, and Physical Activity Recommendations for Weight Management  |  509'],\n",
       "  'page_sentence_count_spacy': 21,\n",
       "  'sentence_chunks': [['overweight children.11 The results of this study were that a higher  percentage of children who made the small changes maintained or  reduced their BMI in comparison to children of families given a  pedometer but not asked to also make physical activity or dietary  changes.12 Several more studies funded by the National Institutes of  Health and USDA are ongoing and are evaluating the effectiveness  of the “small-changes” approach in reducing weight gain.',\n",
       "    ' In 2009, a report of the Joint Task Force of the American Society  for Nutrition, Institute of Food Technologists, and International  Food Information Council proposed that the “small-changes”  approach when supported at the community, industry, and  governmental levels will be more effective than current strategies in  gradually reducing the obesity rate in America.13  11.',\n",
       "    'Rodearmel SJ, Wyatt HR, et al. (',\n",
       "    '2007).',\n",
       "    'Small Changes in  Dietary Sugar and Physical Activity As an Approach to  Preventing Excessive Weight Gain: The America on the  Move Family Study.',\n",
       "    'Pediatrics, 120(4), e869–79.',\n",
       "    ' http://pediatrics.aappublications.org/content/120/4/ e869.long.',\n",
       "    'Accessed September 22, 2017.',\n",
       "    ' 12.',\n",
       "    'Rodearmel SJ, Wyatt HR, et al. ('],\n",
       "   ['2007).',\n",
       "    'Small Changes in  Dietary Sugar and Physical Activity As an Approach to  Preventing Excessive Weight Gain: The America on the  Move Family Study.',\n",
       "    'Pediatrics, 120(4), e869–79.',\n",
       "    ' http://pediatrics.aappublications.org/content/120/4/ e869.long.',\n",
       "    'Accessed September 22, 2017.',\n",
       "    ' 13.',\n",
       "    'Hill JO. (',\n",
       "    '2009).',\n",
       "    'Can a Small-Changes Approach Help  Address the Obesity Epidemic?',\n",
       "    'A Report of the Joint  Task Force of the American Society for Nutrition,  Institute of Food Technologists, and International Food  Information Council.'],\n",
       "   ['American Journal of Clinical  Dietary, Behavioral, and Physical Activity Recommendations for Weight Management  |  509']],\n",
       "  'num_chunks': 3}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(pages_and_text , k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count_row</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>page_sentence_count_spacy</th>\n",
       "      <th>num_chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>562.50</td>\n",
       "      <td>1148.00</td>\n",
       "      <td>199.50</td>\n",
       "      <td>10.52</td>\n",
       "      <td>287.00</td>\n",
       "      <td>10.32</td>\n",
       "      <td>1.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>348.86</td>\n",
       "      <td>560.38</td>\n",
       "      <td>95.83</td>\n",
       "      <td>6.55</td>\n",
       "      <td>140.10</td>\n",
       "      <td>6.30</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-41.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>260.75</td>\n",
       "      <td>762.00</td>\n",
       "      <td>134.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>190.50</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>562.50</td>\n",
       "      <td>1231.50</td>\n",
       "      <td>216.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>307.88</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>864.25</td>\n",
       "      <td>1603.50</td>\n",
       "      <td>272.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>400.88</td>\n",
       "      <td>15.00</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1166.00</td>\n",
       "      <td>2308.00</td>\n",
       "      <td>430.00</td>\n",
       "      <td>39.00</td>\n",
       "      <td>577.00</td>\n",
       "      <td>28.00</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  page_char_count  page_word_count  page_sentence_count_row  \\\n",
       "count      1208.00          1208.00          1208.00                  1208.00   \n",
       "mean        562.50          1148.00           199.50                    10.52   \n",
       "std         348.86           560.38            95.83                     6.55   \n",
       "min         -41.00             0.00             1.00                     1.00   \n",
       "25%         260.75           762.00           134.00                     5.00   \n",
       "50%         562.50          1231.50           216.00                    10.00   \n",
       "75%         864.25          1603.50           272.00                    15.00   \n",
       "max        1166.00          2308.00           430.00                    39.00   \n",
       "\n",
       "       page_token_count  page_sentence_count_spacy  num_chunks  \n",
       "count           1208.00                    1208.00     1208.00  \n",
       "mean             287.00                      10.32        1.53  \n",
       "std              140.10                       6.30        0.64  \n",
       "min                0.00                       0.00        0.00  \n",
       "25%              190.50                       5.00        1.00  \n",
       "50%              307.88                      10.00        1.00  \n",
       "75%              400.88                      15.00        2.00  \n",
       "max              577.00                      28.00        3.00  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(pages_and_text)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting each chunk into its own item\n",
    "\n",
    "We'd like to embed each chunk of sentences into its own numerical representation.\n",
    "\n",
    "So to keep things clean, let's create a new list of dictionaries each containing a single chunk of sentences with relative information such as page number as well statistics about each chunk.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "00%|████████████████████████████████████| 1208/1208 [00:00<00:00, 24538.31it/s]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1843"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "#split each chunk into each item\n",
    "pages_and_chunks =[]\n",
    "for item in tqdm(pages_and_text):\n",
    "    for sentence_chunk in item[\"sentence_chunks\"]:\n",
    "        chunk_dict={}\n",
    "        chunk_dict[\"page_number\"] = item[\"page_number\"]\n",
    "        \n",
    "        #join rge sentences together into a paragraph like structure\n",
    "        joined_sentence_chunk = \"\".join (sentence_chunk).replace(\"  \",\" \").strip()\n",
    "        joined_sentence_chunk = re.sub(r'\\.([A-Z])', r'. \\1', joined_sentence_chunk) # \".A\" -> \". A\" for any full-stop/capital letter combo \n",
    "        chunk_dict[\"sentence_chunk\"] = joined_sentence_chunk\n",
    "        \n",
    "        #get some states on our chunks\n",
    "        chunk_dict[\"chunk_char_count\"] =len(joined_sentence_chunk)\n",
    "        chunk_dict[\"chunk_word_count\"] = len([word for word in joined_sentence_chunk.split(\" \")])\n",
    "        chunk_dict[\"chunk_token_count\"] = len(joined_sentence_chunk)/4\n",
    "        \n",
    "        pages_and_chunks.append(chunk_dict)\n",
    "len(pages_and_chunks)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': 822,\n",
       "  'sentence_chunk': 'successful. Around the world, approximately 40 percent of infants are breastfed exclusively for the recommended 6 months.121314 New mothers must also pay careful consideration to their own nutritional requirements to help their bodies recover in the wake of the pregnancy. This is particularly true for women who breastfeed their babies, which increases the need in certain nutrients. Lactation Preparation for making breast milk, although begun in puberty, is not completed until a woman’s first pregnancy. Early in the first trimester, the cells that will secrete milk divide and multiply. Hormones play a major role in preparing the woman’s body to breastfeed, particularly during the second and third trimesters. At that point, levels of the hormone prolactin increase to stimulate the growth of the milk duct system, which initiates and maintains milk production. Also during pregnancy, progesterone stimulates growth of the alveoli, the clusters of cells where the milk is made. During this process ducts that will carry the milk grow larger and branch out, and new capillaries are also formed to circulate the increased blood supply. However, levels of the hormone progesterone need to decrease for successful milk production, because progesterone 12.',\n",
       "  'chunk_char_count': 1258,\n",
       "  'chunk_word_count': 192,\n",
       "  'chunk_token_count': 314.5}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(pages_and_chunks , k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>chunk_char_count</th>\n",
       "      <th>chunk_word_count</th>\n",
       "      <th>chunk_token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1843.00</td>\n",
       "      <td>1843.00</td>\n",
       "      <td>1843.00</td>\n",
       "      <td>1843.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>583.38</td>\n",
       "      <td>734.10</td>\n",
       "      <td>112.74</td>\n",
       "      <td>183.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>347.79</td>\n",
       "      <td>447.51</td>\n",
       "      <td>71.24</td>\n",
       "      <td>111.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-41.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>280.50</td>\n",
       "      <td>315.00</td>\n",
       "      <td>45.00</td>\n",
       "      <td>78.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>586.00</td>\n",
       "      <td>745.00</td>\n",
       "      <td>115.00</td>\n",
       "      <td>186.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>890.00</td>\n",
       "      <td>1118.00</td>\n",
       "      <td>173.00</td>\n",
       "      <td>279.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1166.00</td>\n",
       "      <td>1830.00</td>\n",
       "      <td>297.00</td>\n",
       "      <td>457.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  chunk_char_count  chunk_word_count  chunk_token_count\n",
       "count      1843.00           1843.00           1843.00            1843.00\n",
       "mean        583.38            734.10            112.74             183.52\n",
       "std         347.79            447.51             71.24             111.88\n",
       "min         -41.00             12.00              3.00               3.00\n",
       "25%         280.50            315.00             45.00              78.75\n",
       "50%         586.00            745.00            115.00             186.25\n",
       "75%         890.00           1118.00            173.00             279.50\n",
       "max        1166.00           1830.00            297.00             457.50"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(pages_and_chunks)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "page number increases to 1843 as there would be chunks belonging to same page as well , thus unique no of pages are still the same\n",
    "\n",
    "Hmm looks like some of our chunks have quite a low token count.\n",
    "\n",
    "How about we check for samples with less than 30 tokens (about the length of a sentence) and see if they are worth keeping?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk token count: 16.75 | Text: PART XI CHAPTER 11. TRACE MINERALS Chapter 11. Trace Minerals | 649\n",
      "Chunk token count: 6.5 | Text: Fat-Soluble Vitamins | 539\n",
      "Chunk token count: 10.5 | Text: 442 | Health Consequences of Alcohol Abuse\n",
      "Chunk token count: 5.25 | Text: Young Adulthood | 907\n",
      "Chunk token count: 3.0 | Text: Iodine | 681\n"
     ]
    }
   ],
   "source": [
    "# Show random chunks with under 30 tokens in length\n",
    "min_token_length = 30\n",
    "for row in df[df[\"chunk_token_count\"] <= min_token_length].sample(5).iterrows():\n",
    "    print(f'Chunk token count: {row[1][\"chunk_token_count\"]} | Text: {row[1][\"sentence_chunk\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like many of these are headers and footers of different pages.\n",
    "\n",
    "They don't seem to offer too much information.\n",
    "\n",
    "Let's filter our DataFrame/list of dictionaries to only include chunks with over 30 tokens in length.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': -39,\n",
       "  'sentence_chunk': 'Human Nutrition: 2020 Edition UNIVERSITY OF HAWAI‘I AT MĀNOA FOOD SCIENCE AND HUMAN NUTRITION PROGRAM ALAN TITCHENAL, SKYLAR HARA, NOEMI ARCEO CAACBAY, WILLIAM MEINKE-LAU, YA-YUN YANG, MARIE KAINOA FIALKOWSKI REVILLA, JENNIFER DRAPER, GEMADY LANGFELDER, CHERYL GIBBY, CHYNA NICOLE CHUN, AND ALLISON CALABRESE',\n",
       "  'chunk_char_count': 308,\n",
       "  'chunk_word_count': 42,\n",
       "  'chunk_token_count': 77.0},\n",
       " {'page_number': -38,\n",
       "  'sentence_chunk': 'Human Nutrition: 2020 Edition by University of Hawai‘i at Mānoa Food Science and Human Nutrition Program is licensed under a Creative Commons Attribution 4.0 International License, except where otherwise noted.',\n",
       "  'chunk_char_count': 210,\n",
       "  'chunk_word_count': 30,\n",
       "  'chunk_token_count': 52.5}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages_and_chunks_over_min_token_len = df[df[\"chunk_token_count\"] > min_token_length].to_dict(orient=\"records\")\n",
    "pages_and_chunks_over_min_token_len[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': 503,\n",
       "  'sentence_chunk': 'high levels of activity (about one hour of exercise per day). Moreover, most members eat breakfast every day, watch fewer than ten hours of television per week, and weigh themselves at least once per week. About half of them lost weight on their own, and the other half used some type of weight-loss program. In most scientific studies successful weight loss is accomplished only by changing the diet and by increasing physical activity. Doing one without the other limits the amount of weight lost and the length of time that weight loss is sustained. On an individual level it is quite possible to achieve successful weight loss, as over ten thousand Americans can attest. Moreover, losing as little as 10 percent of your body weight can significantly improve health and reduce disease risk.4 You do not have to be overweight or obese to reap benefits from eating a healthier diet and increasing physical activity as both provide numerous benefits beyond weight loss and maintenance. Evidence-Based Dietary Recommendations The 2015 Dietary Guidelines for Americans offers specific, evidence-based recommendations for dietary changes aimed at keeping calorie intake in balance with physical activity, which is key for weight management. These recommendations include: Follow a healthy eating pattern that accounts for all foods and beverages within an appropriate calorie level that includes: 4. Clinical Guidelines on the Identification, Evaluation, and Treatment of Overweight and Obesity in Adults: The Evidence Report.',\n",
       "  'chunk_char_count': 1523,\n",
       "  'chunk_word_count': 236,\n",
       "  'chunk_token_count': 380.75}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(pages_and_chunks_over_min_token_len,k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding our text chunks\n",
    "\n",
    "While humans understand text, machines understand numbers best.\n",
    "\n",
    "An [embedding](https://vickiboykis.com/what_are_embeddings/index.html) is a broad concept.\n",
    "\n",
    "But one of my favourite and simple definitions is \"a useful numerical representation\".\n",
    "\n",
    "The most powerful thing about modern embeddings is that they are _learned_ representations.\n",
    "\n",
    "Meaning rather than directly mapping words/tokens/characters to numbers directly (e.g. `{\"a\": 0, \"b\": 1, \"c\": 3...}`), the numerical representation of tokens is learned by going through large corpuses of text and figuring out how different tokens relate to each other.\n",
    "\n",
    "Ideally, embeddings of text will mean that similar meaning texts have similar numerical representation.\n",
    "\n",
    "> **Note:** Most modern NLP models deal with \"tokens\" which can be considered as multiple different sizes and combinations of words and characters rather than always whole words or single characters. For example, the string `\"hello world!\"` gets mapped to the token values `{15339: b'hello', 1917: b' world', 0: b'!'}` using [Byte pair encoding](https://en.wikipedia.org/wiki/Byte_pair_encoding) (or BPE via OpenAI's [`tiktoken`](https://github.com/openai/tiktoken) library). Google has a tokenization library called [SentencePiece](https://github.com/google/sentencepiece).\n",
    "\n",
    "Our goal is to turn each of our chunks into a numerical representation (an embedding vector, where a vector is a sequence of numbers arranged in order).\n",
    "\n",
    "Once our text samples are in embedding vectors, us humans will no longer be able to understand them.\n",
    "\n",
    "However, we don't need to.\n",
    "\n",
    "The embedding vectors are for our computers to understand.\n",
    "\n",
    "We'll use our computers to find patterns in the embeddings and then we can use their text mappings to further our understanding.\n",
    "\n",
    "Enough talking, how about we import a text embedding model and see what an embedding looks like.\n",
    "\n",
    "To do so, we'll use the [`sentence-transformers`](https://www.sbert.net/docs/installation.html) library which contains many pre-trained embedding models.\n",
    "\n",
    "Specifically, we'll get the `all-mpnet-base-v2` model (you can see the model's intended use on the [Hugging Face model card](https://huggingface.co/sentence-transformers/all-mpnet-base-v2#intended-uses)).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: The Sentences Transformers library provides an easy and open-source way to create embeddings.\n",
      "Embedding: [-2.07981411e-02  3.03164814e-02 -2.01218221e-02  6.86483532e-02\n",
      " -2.55255289e-02 -8.47687386e-03 -2.07035700e-04 -6.32377341e-02\n",
      "  2.81606354e-02 -3.33353058e-02  3.02634630e-02  5.30720949e-02\n",
      " -5.03526367e-02  2.62288190e-02  3.33314389e-02 -4.51578423e-02\n",
      "  3.63043919e-02 -1.37109228e-03 -1.20171141e-02  1.14946561e-02\n",
      "  5.04510589e-02  4.70857024e-02  2.11912952e-02  5.14607430e-02\n",
      " -2.03745961e-02 -3.58889513e-02 -6.67914515e-04 -2.94393096e-02\n",
      "  4.95859236e-02 -1.05639827e-02 -1.52013991e-02 -1.31756964e-03\n",
      "  4.48196866e-02  1.56023065e-02  8.60380283e-07 -1.21387048e-03\n",
      " -2.37978902e-02 -9.09456110e-04  7.34487409e-03 -2.53933924e-03\n",
      "  5.23370393e-02 -4.68042940e-02  1.66215282e-02  4.71578613e-02\n",
      " -4.15599458e-02  9.01952444e-04  3.60279121e-02  3.42215039e-02\n",
      "  9.68226939e-02  5.94828613e-02 -1.64984949e-02 -3.51249315e-02\n",
      "  5.92519483e-03 -7.07996951e-04 -2.41031330e-02  3.49741764e-02\n",
      " -2.94746067e-02  6.04272727e-03 -9.80646070e-03  2.83218082e-02\n",
      " -1.85376145e-02  3.63212861e-02  1.30292643e-02 -3.71232964e-02\n",
      "  5.27256802e-02 -1.19706681e-02 -7.18081892e-02  1.24431131e-02\n",
      " -6.70562219e-03  7.42154568e-02  1.16357682e-02 -1.74533576e-02\n",
      " -1.82405729e-02 -1.88930277e-02  2.82414872e-02  1.32828578e-02\n",
      " -3.51910032e-02  8.87303962e-04  5.79571947e-02  3.22093144e-02\n",
      " -3.48586286e-03  4.13768068e-02  1.44357560e-02 -3.28044780e-02\n",
      " -9.79082379e-03 -3.16493884e-02  4.23871167e-02 -4.70847525e-02\n",
      " -2.08937842e-02 -1.91250574e-02 -1.22627094e-02  1.01604946e-02\n",
      "  3.91922072e-02 -2.61895489e-02  1.09028183e-02  1.35722645e-02\n",
      " -5.79266697e-02 -3.21500190e-02 -5.75723127e-03 -2.43516210e-02\n",
      "  5.23417108e-02  5.46129933e-03 -2.30996814e-02  2.57173507e-03\n",
      " -6.63346127e-02  3.54126282e-02 -1.03907762e-02  2.25409660e-02\n",
      " -1.84574444e-02 -2.42006052e-02 -4.78365198e-02 -4.79244208e-03\n",
      " -5.34137562e-02  3.01791150e-02 -1.56130549e-02 -5.51475994e-02\n",
      " -3.91875058e-02  5.92153035e-02 -3.47646847e-02  9.68123041e-03\n",
      "  2.13416182e-02  2.30417401e-02  1.91712100e-02  2.77379248e-02\n",
      " -7.73511594e-03  1.04445554e-02 -2.67719906e-02 -2.40199026e-02\n",
      " -1.92289930e-02  3.91500071e-03 -2.54714917e-02  3.61943282e-02\n",
      "  5.12867384e-02 -8.41697305e-03 -3.13829482e-02  1.47484429e-02\n",
      "  2.13939622e-02 -3.84901129e-02  2.01945901e-02  1.20765474e-02\n",
      " -3.12088290e-03  7.84028601e-03  3.30342143e-03 -4.94357385e-02\n",
      "  5.83887100e-02  3.26128770e-03  4.84482432e-03 -4.50681299e-02\n",
      "  2.45682616e-02  3.55427451e-02 -5.32505848e-02  9.21152905e-02\n",
      "  2.04395466e-02 -3.36951837e-02 -6.19804151e-02 -2.11038850e-02\n",
      "  7.82359838e-02  5.11908159e-02  5.93170524e-02 -1.25068895e-04\n",
      "  4.96348962e-02 -1.55722499e-02 -3.35676433e-03  1.82015728e-02\n",
      " -2.73444075e-02 -1.08771687e-02  1.41476076e-02  1.09877139e-02\n",
      "  4.32551745e-03  8.23311806e-02 -9.85419611e-04  7.58791342e-02\n",
      "  9.44992434e-03  2.37687938e-02  1.61929317e-02  6.24994636e-02\n",
      "  4.75922823e-02 -3.92621243e-03  9.07523856e-02  4.49874066e-02\n",
      " -3.47131491e-02  2.14077644e-02 -3.35604399e-02  4.93850484e-02\n",
      "  1.08670024e-02  2.63447426e-02 -3.26089375e-02  8.00303370e-02\n",
      "  9.29762051e-03  7.16571510e-03 -2.79171914e-02 -3.06820869e-02\n",
      "  4.01064055e-03 -4.93906625e-02 -3.13775335e-03  4.00537252e-02\n",
      " -3.97855341e-02  5.48014604e-02  1.35884893e-05 -8.38373899e-02\n",
      " -1.21547412e-02  3.40949968e-02  3.22402944e-03  6.11846298e-02\n",
      "  5.60066402e-02  9.62875038e-03  2.54616309e-02 -4.64168973e-02\n",
      " -3.98900658e-02  7.68132731e-02  2.28408724e-02 -2.26567276e-02\n",
      " -1.91192981e-02 -6.53027669e-02  4.56781201e-02 -4.43660840e-03\n",
      "  1.49631491e-02 -2.15078592e-02  2.74239713e-03  1.90359019e-02\n",
      "  5.91888055e-02 -2.47569121e-02  3.66144963e-02  5.63083626e-02\n",
      " -8.86445399e-03 -1.74325518e-02 -1.03289378e-03  2.47667693e-02\n",
      "  1.30763371e-02  5.04633375e-02 -5.28492546e-03  5.92396855e-02\n",
      "  6.29906356e-02 -4.36783433e-02 -4.97831888e-02  5.56297228e-02\n",
      " -2.44854484e-02 -8.26755688e-02  2.04911567e-02 -1.06446326e-01\n",
      "  6.64835097e-03  2.97303461e-02 -2.36440338e-02 -8.84612836e-03\n",
      "  2.45558284e-03 -3.35234702e-02  7.52213076e-02 -5.89880086e-02\n",
      " -3.67808230e-02  3.41542661e-02  5.41130193e-02 -1.74905229e-02\n",
      "  1.33920601e-02  4.71682250e-02  1.46117033e-02 -2.12310702e-02\n",
      " -6.55339584e-02  1.23857874e-02  2.76075024e-02 -8.02160706e-03\n",
      " -4.59636450e-02 -8.22449010e-03  9.16955899e-03 -1.56398527e-02\n",
      "  7.54615199e-03  1.58317864e-03 -3.03959530e-02 -5.10671847e-02\n",
      "  1.96313243e-02  1.26263369e-02 -1.51735428e-03  2.02890877e-02\n",
      "  1.37817832e-02  1.49110621e-02  2.50766519e-02 -3.62871103e-02\n",
      "  1.08084520e-02  2.74132797e-03  1.81510337e-02  5.39872050e-02\n",
      " -4.74542044e-02 -4.28731069e-02 -2.89914850e-02  2.13234797e-02\n",
      " -3.85161676e-02  6.31922260e-02 -5.77976182e-02  3.77890165e-03\n",
      " -2.54394747e-02 -1.77195747e-04  9.08244587e-03  1.59095861e-02\n",
      "  4.11798656e-02 -3.94369215e-02 -9.64433327e-03  1.30792009e-02\n",
      "  6.87962323e-02  4.32193242e-02  7.54087872e-04  6.77741915e-02\n",
      "  4.93705943e-02 -3.47821042e-03 -1.06054442e-02  6.72494248e-03\n",
      " -1.39062526e-02  4.88276742e-02 -1.05735948e-02  3.50230793e-03\n",
      "  2.90217670e-03  2.40043998e-02  1.20272897e-02 -2.09796410e-02\n",
      " -2.39112433e-02  3.26578915e-02 -1.01319375e-03 -5.92754129e-03\n",
      " -7.40533695e-03  3.63134174e-03 -2.26698294e-02 -2.21242551e-02\n",
      "  3.86995636e-02  1.72322337e-02  3.85921597e-02 -5.04710898e-02\n",
      " -3.42144594e-02 -4.00442891e-02 -3.57910432e-02 -4.62560691e-02\n",
      "  6.70232475e-02 -4.61650081e-03 -3.29678296e-03  2.08444018e-02\n",
      " -5.14254998e-03 -5.00850417e-02  2.22504269e-02  4.66933846e-02\n",
      "  1.36208124e-02  1.77530833e-02  4.28085914e-03 -2.79332120e-02\n",
      " -1.93421226e-02 -3.87860537e-02 -3.09555698e-02 -6.64132833e-02\n",
      " -1.13433963e-02  1.64267272e-02  1.77629814e-02 -2.28230958e-03\n",
      " -3.30087878e-02 -1.36266602e-03 -2.17933860e-02 -2.67508607e-02\n",
      " -1.26376059e-02  1.61867193e-03 -4.95672822e-02  7.85445273e-02\n",
      "  4.10961695e-02  9.65923164e-03 -1.14643229e-02  1.68855919e-03\n",
      "  5.37663810e-02  2.05534813e-03 -4.11201790e-02  1.46330381e-02\n",
      " -3.75564285e-02 -3.35689522e-02  5.19258529e-03 -6.33089170e-02\n",
      "  3.32963839e-02  8.76120105e-03  1.33855548e-03 -3.95747786e-03\n",
      " -1.61677729e-02  8.26746374e-02  4.75944728e-02 -3.43055315e-02\n",
      "  2.50881836e-02 -3.50976400e-02  3.68657112e-02  4.12653014e-03\n",
      "  4.16018665e-02 -1.35181785e-01 -4.76337560e-02 -1.20025733e-02\n",
      " -3.48892175e-02  3.25454362e-02 -2.93571409e-03 -4.85051377e-03\n",
      " -1.04223825e-01  2.78610475e-02  1.41570168e-02  3.94396111e-02\n",
      " -3.88806425e-02 -1.42463772e-02 -5.19984514e-02  8.92738719e-03\n",
      " -1.99771244e-02 -2.51724850e-02 -3.41300480e-02  1.93040967e-02\n",
      " -5.20207584e-02 -6.71999529e-02 -9.46363993e-03 -1.25586963e-03\n",
      " -5.66048436e-02  2.62097958e-02  9.91584081e-03  4.38287631e-02\n",
      "  2.26640608e-03 -3.11896577e-02 -6.25468791e-02 -3.87792252e-02\n",
      " -6.83938712e-02  4.93722707e-02  5.85507974e-02 -4.08730283e-02\n",
      " -1.98638607e-02 -2.12635100e-02  4.98037487e-02 -4.51748110e-02\n",
      " -2.37141438e-02  2.32674610e-02  1.00594826e-01  9.87114105e-03\n",
      " -1.38013968e-02 -5.21041043e-02  9.08209290e-03  1.72428042e-02\n",
      "  5.91432191e-02  2.62337346e-02 -7.04637868e-03 -1.50031885e-02\n",
      " -3.76657187e-03  6.28260849e-03 -5.23982719e-02 -4.96638231e-02\n",
      "  3.06610763e-02 -3.33642215e-03  2.34911907e-02 -8.58829841e-02\n",
      " -4.62449305e-02  5.59701137e-02  3.09034251e-04  2.01728735e-02\n",
      " -2.98066647e-03  1.76645648e-02  1.54669350e-02 -7.41719306e-02\n",
      "  7.34985573e-03 -1.05013978e-02  2.45247353e-02  1.36879431e-02\n",
      " -1.17803561e-02  4.51544039e-02  3.29039395e-02 -3.50393238e-03\n",
      " -2.71315724e-02 -5.27364872e-02 -4.60164808e-02  2.22849734e-02\n",
      "  2.62272730e-02  5.56150544e-03  1.45788193e-02 -2.97144838e-02\n",
      "  3.57042663e-02  2.22534239e-02  3.89618091e-02 -7.92635158e-02\n",
      " -9.01090540e-03  2.19012778e-02 -5.49063226e-03  8.69965646e-03\n",
      "  4.33030687e-02 -2.12631766e-02  1.13292364e-02 -6.33699298e-02\n",
      "  3.63723114e-02  2.67442726e-02 -6.64251000e-02  1.70500055e-02\n",
      " -2.79692095e-02  2.36353069e-03 -1.81953404e-02  1.52954999e-02\n",
      " -8.50430317e-03  1.16648469e-02 -9.75922346e-02 -2.92093307e-02\n",
      " -5.42547107e-02  3.61234620e-02  3.25115435e-02  8.26974772e-03\n",
      " -2.96543643e-04  1.11556025e-02 -3.85188982e-02  2.36161929e-02\n",
      "  9.85917822e-03  5.73998354e-02  4.86060008e-02 -1.37579776e-02\n",
      " -6.19214587e-03  1.11972485e-02 -3.37175131e-02 -1.10515682e-02\n",
      " -7.08333403e-02 -1.01816906e-02 -3.66010815e-02 -1.55561240e-02\n",
      " -2.13109273e-02 -1.02760019e-02 -4.35734130e-02  5.55186234e-02\n",
      " -3.76547314e-02  5.29252179e-02 -3.45224552e-02 -2.43013934e-03\n",
      "  7.25553036e-02  4.45071096e-03  4.71416079e-02 -9.43879131e-03\n",
      " -1.98978111e-02  5.71899302e-02  8.60540494e-02 -5.25058173e-02\n",
      " -1.39550585e-02  1.17373643e-02  1.33974273e-02 -4.73052561e-02\n",
      " -5.41673712e-02  4.62725535e-02 -2.58970950e-02  1.51415868e-02\n",
      "  3.38944048e-02 -3.78252612e-03 -5.76043203e-02 -1.60082616e-02\n",
      "  2.42738444e-02  3.37360129e-02 -1.96821280e-02 -2.53464654e-02\n",
      " -4.75616977e-02 -5.68756089e-02 -2.28193700e-02  3.83186750e-02\n",
      " -1.78330801e-02  1.35962814e-02  7.85983982e-04  9.74011421e-03\n",
      "  3.34298648e-02 -2.60134637e-02 -7.38569582e-03  3.56451273e-02\n",
      " -2.68531796e-02 -7.53623992e-02 -2.66983788e-02 -4.46457787e-33\n",
      " -3.31645384e-02  1.41703943e-02 -3.92909087e-02 -3.46318074e-02\n",
      " -5.88679779e-03 -1.18212486e-02  1.53950844e-02  1.18474634e-02\n",
      "  1.07757989e-02  3.62141058e-02  7.87955895e-03 -2.31845006e-02\n",
      "  1.07623069e-02  1.72345266e-02  9.54219839e-04  2.83640809e-02\n",
      "  2.37420369e-02 -1.48057006e-02  1.24199281e-03  3.52354674e-03\n",
      "  2.33735628e-02  5.58308028e-02  5.38328402e-02 -3.74078490e-02\n",
      " -2.11805161e-02  1.52705659e-04 -7.27783842e-03  5.50560514e-03\n",
      "  3.05824336e-02  4.54633869e-02 -3.35787050e-02  3.16142179e-02\n",
      " -2.56392895e-03  3.96354906e-02 -1.47572421e-02  5.67167141e-02\n",
      " -5.62787689e-02 -5.04599465e-03  3.56154516e-02 -2.76199523e-02\n",
      " -2.32292209e-02 -4.63292636e-02 -3.70919965e-02 -4.23188694e-02\n",
      "  3.70306186e-02  7.88718183e-03  3.85176614e-02  1.74775335e-03\n",
      "  5.62762748e-03  6.18104311e-03 -6.90269321e-02 -9.42970160e-03\n",
      " -7.74672907e-03  1.68350488e-02  1.22766877e-02  2.26407181e-02\n",
      "  1.21009164e-02  1.11743705e-02  1.21538769e-02 -1.16862264e-02\n",
      " -4.41612266e-02  2.30048075e-02  2.20671613e-02 -5.87505065e-02\n",
      " -3.96428369e-02  6.83134943e-02 -3.29948552e-02 -3.66774388e-02\n",
      " -3.53655852e-02  1.76184960e-02  6.95644086e-03  5.92692494e-02\n",
      "  4.12155949e-02  7.98109472e-02 -5.36567578e-03  1.14238160e-02\n",
      " -2.96389144e-02 -1.15411989e-02  2.22811792e-02  7.93191139e-03\n",
      "  2.60356367e-02  1.28212059e-02  1.71346348e-02 -6.90191844e-03\n",
      " -1.07603790e-02  1.35715595e-02 -9.90764471e-04 -6.16075136e-02\n",
      "  4.40513529e-02 -8.26502044e-04 -2.78341454e-02 -1.23619512e-02\n",
      "  1.34629672e-02 -3.85745429e-02  1.08704786e-03  2.18712818e-02\n",
      " -3.32398899e-02  1.84615292e-02 -5.10105584e-03  3.74664888e-02\n",
      " -3.67547153e-03 -2.19246950e-02 -4.96482570e-03 -9.59827099e-03\n",
      "  2.33591422e-02  1.04876310e-02  4.38722149e-02 -1.51424622e-02\n",
      " -6.30309880e-02  8.23262054e-03 -1.09130945e-02 -4.06409353e-02\n",
      " -6.21690676e-02  2.21326258e-02 -2.71434449e-02  4.05540131e-02\n",
      " -8.09447560e-03 -1.76410039e-03  3.01525909e-02 -5.42267412e-03\n",
      " -4.69822250e-02 -1.73768289e-02  4.11631316e-02  3.20636220e-02\n",
      " -2.22944003e-02 -1.58162042e-02 -4.50720601e-02  5.69486357e-02\n",
      "  4.71596457e-02 -5.78059070e-02  1.32474834e-02 -4.71284427e-03\n",
      "  1.66824591e-07  4.81090210e-02  5.03628179e-02  5.45264445e-02\n",
      "  2.07568705e-02 -1.19081317e-02 -6.37492863e-03  5.26375044e-03\n",
      "  7.21949041e-02 -2.21763253e-02  2.20102966e-02 -9.90452245e-04\n",
      " -1.37162833e-02  6.89207390e-03  2.46912371e-02 -1.39462024e-01\n",
      "  2.56979442e-03 -4.64828089e-02 -4.04967666e-02 -6.08556122e-02\n",
      " -1.53212901e-02  1.36129856e-01  9.45034325e-02  4.25741449e-02\n",
      "  4.67131473e-02 -2.30677240e-02 -1.20965485e-02  3.86673585e-02\n",
      "  2.11663754e-03 -2.51472909e-02 -1.15076294e-02 -3.46506685e-02\n",
      " -2.29534339e-02 -6.33849762e-03 -3.05175465e-02 -1.56236580e-02\n",
      "  1.39513761e-02  3.27491754e-04  2.00334867e-03  4.15105652e-03\n",
      " -2.22925283e-02 -3.62589024e-02 -2.36578751e-02 -1.87817682e-02\n",
      " -1.96288731e-02  4.52125743e-02 -8.12569931e-02 -2.14568954e-02\n",
      " -4.41542752e-02 -2.68476456e-02  2.01974697e-02  2.82994588e-03\n",
      " -1.95011403e-02 -3.45331058e-02  2.26913821e-02  3.78325358e-02\n",
      " -1.02543915e-02 -2.19744141e-03 -8.96744505e-02 -4.50030342e-02\n",
      "  8.09698272e-03 -2.05805264e-02 -2.02997793e-02 -2.09922623e-02\n",
      " -1.79405082e-02  5.81897497e-02 -7.63651449e-03  1.50847109e-02\n",
      "  1.78279847e-34  4.86179255e-02  4.22228016e-02  4.71596010e-02\n",
      "  5.89047149e-02  3.99783999e-02 -5.27070761e-02  1.56905577e-02\n",
      " -5.25080424e-04  1.13652358e-02 -6.56410977e-02 -2.20849942e-02]\n",
      "\n",
      "Sentence: Sentences can be embedded one by one or as a list of strings.\n",
      "Embedding: [ 4.31718044e-02 -5.38701452e-02 -3.78044732e-02  4.27235849e-02\n",
      " -2.35409737e-02  3.44861113e-02  2.89587826e-02  1.92811759e-03\n",
      "  2.41732225e-02 -3.17011960e-02  7.32856244e-02  1.25589762e-02\n",
      "  3.64620611e-02 -2.05251705e-02  2.81973705e-02 -6.87329099e-02\n",
      "  4.22230996e-02  9.31745046e-04  3.54035385e-02  1.41787305e-02\n",
      "  7.83992652e-03  2.31179316e-02 -4.84740036e-03  1.07174329e-02\n",
      "  4.39493824e-03  5.47808874e-03 -3.80339064e-02 -3.05487402e-03\n",
      "  5.72234346e-03 -6.78214207e-02 -4.88007814e-02 -1.45031810e-02\n",
      "  6.68004388e-03 -7.17479661e-02  1.64644973e-06  1.07563799e-02\n",
      " -3.60922441e-02 -2.37057172e-02 -5.22792339e-02  3.46110165e-02\n",
      " -5.42170042e-03  1.62611399e-02  1.96564645e-02  2.25395449e-02\n",
      " -2.25996319e-03  4.06342633e-02  8.17157850e-02  2.48179529e-02\n",
      "  5.31884059e-02  7.82714933e-02 -1.91813372e-02 -1.94086935e-02\n",
      " -2.62805447e-02 -2.44083479e-02  5.49406260e-02  1.90318711e-02\n",
      "  1.60811096e-02 -2.68895421e-02 -8.24687723e-03  7.33444244e-02\n",
      "  1.00122970e-02  2.93315127e-02  3.42869153e-03 -2.13270206e-02\n",
      " -1.62442203e-03 -5.56258811e-03 -7.64879957e-02 -5.85450232e-02\n",
      " -2.82272175e-02  7.51852756e-03  7.11226314e-02  1.95452850e-03\n",
      "  5.45923132e-03  3.22309416e-03  5.12800626e-02 -3.54105420e-02\n",
      " -5.03608696e-02  4.70519289e-02  5.15476987e-03  1.52287195e-02\n",
      " -1.06680766e-02  3.16299610e-02 -9.09038354e-03 -4.01326828e-02\n",
      " -4.35235985e-02 -1.94969252e-02  1.65604874e-02 -4.71168309e-02\n",
      " -3.92091423e-02 -3.07756942e-02 -2.94167213e-02 -4.20826375e-02\n",
      "  2.27079936e-03 -2.78329551e-02  1.69421472e-02  7.74499541e-03\n",
      " -5.23741841e-02 -4.50039990e-02  3.83605696e-02 -4.90787067e-02\n",
      "  5.06618731e-02  1.01615656e-02 -1.25021935e-02 -4.64553246e-03\n",
      " -1.54539226e-02  1.58862732e-02  1.18369386e-02 -3.59232537e-02\n",
      " -7.76226446e-02  3.43359224e-02 -2.14709770e-02 -6.86098859e-02\n",
      " -5.46235740e-02  7.83901215e-02 -3.00703365e-02 -3.37549932e-02\n",
      " -4.04999107e-02  4.80515063e-02  9.53899324e-03  2.31399089e-02\n",
      " -8.16115886e-02 -6.51692227e-03  1.54212778e-02  7.04257190e-02\n",
      " -1.25068622e-02 -2.48266384e-02 -1.71329286e-02  6.13109767e-03\n",
      "  5.44413105e-02 -1.40566267e-02 -6.24518748e-03  3.65787297e-02\n",
      "  7.36230314e-02 -6.05682889e-03 -3.61630209e-02 -1.42203912e-03\n",
      "  4.43165451e-02 -3.14516388e-03  3.18768285e-02 -1.30948182e-02\n",
      " -3.69524583e-02 -4.98030707e-03  1.30016741e-03 -2.05213353e-02\n",
      "  2.06277575e-02  5.93871577e-03 -3.07161734e-03 -3.97511981e-02\n",
      "  4.29890119e-02  6.49802312e-02 -6.76022843e-02  5.41655645e-02\n",
      "  1.52571930e-03 -3.72908749e-02 -4.02427800e-02 -2.28771623e-02\n",
      "  1.31769866e-01  4.87876358e-03  1.39470724e-02  4.92436066e-02\n",
      "  2.49219723e-02 -8.76093749e-03 -5.38768200e-03 -2.65595056e-02\n",
      " -1.19766789e-02 -2.32006870e-02 -2.67433655e-02  5.66912210e-03\n",
      "  2.21722275e-02  4.67294268e-02 -5.78486547e-02  8.22120160e-02\n",
      " -3.36839515e-03  8.09646919e-02  1.41423335e-02  1.02393106e-01\n",
      " -5.76834520e-03 -1.15877325e-02  4.90584634e-02  5.87829687e-02\n",
      "  6.50030077e-02  4.74622399e-02 -2.89464239e-02 -1.76578586e-03\n",
      "  3.32560688e-02  2.91198008e-02  6.03811406e-02  3.73474380e-04\n",
      "  1.06576048e-02 -5.96284047e-02 -7.28600845e-02  2.95080487e-02\n",
      "  9.54462681e-03 -2.71541439e-02 -5.63305393e-02  9.66691179e-04\n",
      " -4.77728732e-02  4.67576608e-02  4.87261033e-03 -6.57519773e-02\n",
      " -1.42248739e-02  3.99872586e-02 -1.09798731e-02  7.68942833e-02\n",
      " -4.00003642e-02  2.96826698e-02  2.81303953e-02 -5.55424243e-02\n",
      "  6.31275401e-03  5.00450917e-02  1.89884249e-02  5.38683608e-02\n",
      " -1.95981823e-02  1.08600892e-02  1.64150242e-02  1.44135291e-02\n",
      "  1.71448551e-02  2.17624642e-02 -4.98863310e-02  1.56105887e-02\n",
      "  4.83738491e-03  1.87053736e-02 -3.18552880e-03  2.66863219e-02\n",
      "  5.55552393e-02 -4.88005430e-02 -3.02928910e-02  2.52110325e-02\n",
      "  1.07264845e-02  1.88270509e-02 -1.50688086e-02  3.43831815e-02\n",
      "  4.15124819e-02  1.37788747e-02 -5.54848015e-02  1.43847903e-02\n",
      " -5.88140227e-02 -6.01676106e-02  2.69856527e-02 -5.46129905e-02\n",
      "  8.14636145e-03 -1.17758885e-02  1.57441888e-02  1.43902993e-03\n",
      " -2.64554806e-02 -4.48877178e-02  4.39732820e-02 -1.06196196e-04\n",
      " -2.25905199e-02  3.00295819e-02  1.97440535e-02  7.44070392e-03\n",
      " -1.93789862e-02  8.09794851e-03  4.34860475e-02 -1.08539622e-04\n",
      " -3.77225988e-02  2.67195720e-02 -4.63157855e-02 -1.53398095e-03\n",
      "  8.05307273e-03 -4.30901684e-02 -2.13848483e-02  1.20185316e-02\n",
      "  8.41398258e-03  2.48266989e-03 -3.09566353e-02 -9.05277058e-02\n",
      " -4.76693697e-02  1.22606605e-02 -1.36466864e-02 -2.63655167e-02\n",
      " -7.65552092e-03  8.72374233e-03  2.65724733e-02  8.40085733e-04\n",
      " -5.55930333e-03 -9.29541420e-03  3.19337659e-02  5.94646409e-02\n",
      "  1.83205567e-02 -7.56546780e-02 -5.59389405e-02 -1.20871281e-02\n",
      " -3.16260494e-02  3.62186916e-02  7.53609836e-03 -6.15654588e-02\n",
      " -2.30459105e-02 -3.51670152e-03  1.23332078e-02 -9.67647694e-03\n",
      "  4.96861376e-02 -8.42256770e-02  1.52395796e-02 -1.82445142e-02\n",
      "  7.70462304e-02  9.28718075e-02  4.03725132e-02  1.11732587e-01\n",
      " -1.03270635e-02 -2.54558902e-02  2.13153344e-02 -1.16184435e-03\n",
      "  2.82593933e-03  5.06967008e-02 -3.13697197e-02 -8.14281777e-03\n",
      "  1.38386479e-02  4.66889851e-02  5.09671234e-02  3.77154201e-02\n",
      " -2.94988751e-02  3.60631980e-02 -2.61168275e-03  2.72210309e-04\n",
      " -6.71807751e-02 -6.54026568e-02 -3.43590975e-02  1.91068090e-02\n",
      "  4.13293801e-02 -1.10971006e-02  4.51952666e-02 -5.93564771e-02\n",
      "  1.06963571e-02 -1.82229802e-02 -5.65814152e-02  1.20387580e-02\n",
      "  4.44775000e-02  1.87049843e-02  1.63810104e-02  5.51151074e-02\n",
      " -2.23332513e-02  2.12861244e-02 -1.20339599e-02  3.26752812e-02\n",
      "  1.47003364e-02 -8.16685427e-03  1.12904646e-02 -3.00620701e-02\n",
      " -2.34345198e-02 -2.68646721e-02 -1.28718745e-03 -7.67190307e-02\n",
      "  2.22610449e-03 -5.89485187e-03  2.63103880e-02  2.07133056e-03\n",
      " -6.91152215e-02 -1.43792266e-02  2.68788934e-02 -3.51540223e-02\n",
      " -2.69612391e-02  2.54720007e-03 -6.48881346e-02  3.18728089e-02\n",
      "  1.70127023e-02 -4.54004444e-02 -1.80615988e-02 -1.61116645e-02\n",
      "  5.70773073e-02 -2.78269802e-03 -6.45586774e-02  7.86598027e-02\n",
      "  2.29076073e-02  6.81844028e-03 -9.11738910e-03 -2.27726474e-02\n",
      " -4.76526320e-02  4.88431081e-02 -2.09891386e-02 -2.43694074e-02\n",
      " -5.01213269e-03  6.70254007e-02  6.91373181e-03  2.25842930e-02\n",
      "  2.51125563e-02 -6.92507485e-03  8.59399140e-03  2.38977373e-02\n",
      "  3.29738297e-02 -1.05310544e-01  1.22094564e-02 -1.22263497e-02\n",
      " -5.73768578e-02  1.84311196e-02  2.97157578e-02 -6.09429218e-02\n",
      " -6.55256733e-02  3.55713032e-02  5.64321363e-03  3.34648113e-03\n",
      " -3.59686315e-02 -8.83420464e-03 -6.97894692e-02  6.89779818e-02\n",
      " -4.88209166e-03  2.23995298e-02 -3.16053927e-02 -7.41184223e-03\n",
      "  3.19351330e-02 -5.18788807e-02  2.11601369e-02 -5.03340587e-02\n",
      "  9.10579320e-03  2.13354342e-02  1.66838244e-02  3.49019878e-02\n",
      " -6.38500750e-02 -6.75629312e-03 -1.27405152e-02 -4.63366508e-02\n",
      " -1.14779919e-02  2.08778568e-02  2.44822986e-02  3.66473012e-03\n",
      " -2.86100898e-03  2.29388550e-02  2.13745795e-02 -3.48900743e-02\n",
      " -3.00388113e-02  4.78870571e-02  5.83370142e-02 -9.70495120e-03\n",
      "  1.38234068e-02 -3.27485576e-02 -8.11435864e-04  9.54225101e-03\n",
      "  1.20401718e-02  1.97231174e-02 -4.74879809e-04 -1.39225526e-02\n",
      " -5.21069840e-02 -1.75592341e-02 -5.41698895e-02 -1.17969504e-02\n",
      " -1.71030220e-02 -3.50195244e-02  3.38661373e-02 -6.76587224e-02\n",
      " -2.27607340e-02  1.95606481e-02  5.50250337e-02  1.22029129e-02\n",
      " -1.75167667e-03  7.22440798e-03  1.16349757e-02 -1.61908567e-02\n",
      " -3.37755382e-02  3.22626717e-02 -2.03813985e-02 -2.33858712e-02\n",
      " -1.29991733e-02 -1.66799836e-02  1.03070559e-02 -1.46030430e-02\n",
      " -7.79071152e-02 -8.25812370e-02 -3.38809900e-02  3.81114371e-02\n",
      "  7.86005519e-03  2.41455156e-02 -2.75715515e-02  1.30867753e-02\n",
      " -7.88597390e-03  1.78652015e-02  5.37323765e-02 -3.01823094e-02\n",
      "  1.69455484e-02  1.19570866e-02  3.52530682e-04  4.90209050e-02\n",
      " -8.57211184e-03  1.71267707e-03  4.83880006e-03 -4.10080217e-02\n",
      " -4.68119793e-02 -2.32556858e-03 -5.16775995e-02  3.10030542e-02\n",
      "  1.60961561e-02 -1.00803375e-02 -3.72483116e-03 -3.53388526e-02\n",
      "  2.95960978e-02  2.89097819e-02 -7.59911761e-02 -5.02981320e-02\n",
      " -2.11783499e-02  3.20462175e-02 -3.84538285e-02  2.45102532e-02\n",
      " -2.04188637e-02  6.02113316e-03 -9.81937349e-03  3.74778472e-02\n",
      "  3.40838619e-02  1.28863826e-02  5.67341968e-02 -8.09703395e-02\n",
      " -8.93602241e-03  1.33352950e-02 -2.51566060e-02  2.58414354e-03\n",
      " -6.51802048e-02  1.34400865e-02 -2.04682127e-02  6.53380342e-03\n",
      "  4.56972932e-03  1.99271683e-02 -6.07340224e-02  1.40691744e-02\n",
      " -5.75334206e-02  9.79802012e-03  3.55393030e-02 -2.45283544e-02\n",
      " -4.73312335e-03 -2.77492907e-02  2.34283060e-02 -8.76143313e-05\n",
      "  7.30440160e-03  1.42028863e-02  4.92806993e-02 -3.16540301e-02\n",
      " -1.34902503e-02  3.08487788e-02  2.80401763e-02 -4.33069132e-02\n",
      " -4.42284532e-02  3.80738862e-02  9.47262961e-05 -4.34896164e-02\n",
      "  1.43867368e-02  2.44332151e-03 -4.84072939e-02  1.08955568e-02\n",
      " -9.87493619e-03  4.59295176e-02  3.96379307e-02 -2.60116979e-02\n",
      "  2.48134118e-02 -5.37149422e-02  5.62824234e-02  8.81362054e-03\n",
      "  5.25076985e-02 -1.47370771e-02 -1.74380988e-02  3.45084444e-02\n",
      "  3.75523195e-02 -4.70167547e-02 -1.94911100e-02  3.82631756e-02\n",
      " -5.67596108e-02 -1.78615469e-03  2.33404543e-02 -5.88216602e-33\n",
      " -4.87188175e-02 -2.76265573e-02 -3.38240899e-02  2.66188476e-02\n",
      " -3.39277387e-02 -8.49186443e-03 -1.91250816e-02  3.00252605e-02\n",
      "  3.40781882e-02  5.11158146e-02 -1.92480031e-02  2.85642520e-02\n",
      "  3.66040505e-02  1.68858077e-02  4.77258675e-02  1.23802088e-02\n",
      "  2.14843657e-02  4.93653701e-04  1.21273780e-02 -5.82143962e-02\n",
      "  1.62954777e-02 -7.14258058e-03  4.80092727e-02  2.51190849e-02\n",
      "  4.60097902e-02 -2.29839869e-02 -2.05696113e-02 -3.22234351e-03\n",
      "  4.00092676e-02  3.52309458e-02 -3.43153886e-02  2.75630993e-03\n",
      " -1.25138285e-02  1.97685231e-02  5.53493435e-03  1.03744492e-01\n",
      "  5.77613153e-03 -5.65426573e-02  4.19558808e-02 -3.78830731e-02\n",
      " -3.93443145e-02 -6.24309592e-02 -2.24389695e-03 -5.46548590e-02\n",
      "  4.56133783e-02 -5.69241680e-03  3.38917002e-02 -1.44448243e-02\n",
      "  2.72104144e-03  1.11190975e-02 -5.00661880e-02 -1.61127243e-02\n",
      "  1.72818976e-03  6.88878000e-02  1.16492817e-02  2.83171441e-02\n",
      "  6.97189104e-03  2.68371757e-02 -7.72081316e-03  2.16828398e-02\n",
      "  1.15182931e-02  8.72832984e-02 -6.27269829e-03 -6.44473210e-02\n",
      " -1.58233363e-02  4.03268747e-02 -1.69728547e-02 -1.61188655e-02\n",
      " -3.75576578e-02  7.02938214e-02 -3.30486111e-02  4.66323979e-02\n",
      "  1.18028112e-02  6.51075467e-02 -1.16979126e-02 -8.28348193e-03\n",
      " -5.46905845e-02 -2.00227071e-02  8.42718757e-04 -8.19522049e-03\n",
      "  2.08357964e-02  1.37454038e-02 -1.29922677e-03 -3.94575484e-02\n",
      " -2.00185087e-02 -1.53721608e-02  1.17271692e-02 -4.40111309e-02\n",
      "  5.39267175e-02 -2.33010780e-02 -2.24211067e-02 -3.65214678e-03\n",
      "  2.92213131e-02  7.56441709e-03 -2.90923864e-02  4.01517600e-02\n",
      " -2.00853739e-02 -1.79861067e-03 -1.26236556e-02  2.51077190e-02\n",
      " -4.69286218e-02 -3.08553372e-02 -3.63375439e-04  6.01791497e-03\n",
      "  3.97508964e-02  1.38547355e-02  2.49774493e-02  1.76975224e-02\n",
      " -9.31573436e-02 -9.83684696e-03  8.44927412e-03 -1.95390582e-02\n",
      " -3.26568782e-02  5.13737090e-03  5.80932712e-03  2.08536461e-02\n",
      " -5.97834494e-03  5.86811677e-02 -1.49495509e-02 -5.72965741e-02\n",
      " -5.98234124e-03  1.95204420e-03  2.72979285e-03  6.07007090e-03\n",
      " -2.00525876e-02 -1.31687447e-02 -4.06229012e-02  5.68997897e-02\n",
      "  4.44969460e-02 -1.24308625e-02  1.96967628e-02  3.80980112e-02\n",
      "  2.30237688e-07  1.10575091e-02  4.79513071e-02  6.18298836e-02\n",
      "  4.40278985e-02  6.17667381e-03  2.58291373e-03  3.38913612e-02\n",
      " -5.32938167e-03 -2.59283744e-02 -1.26144439e-02  2.46495474e-02\n",
      " -1.68771681e-03  1.17911934e-03  2.40443107e-02 -9.77309421e-02\n",
      "  1.97368003e-02 -5.52921928e-02 -6.17424771e-02 -4.87151854e-02\n",
      "  1.11079076e-03  1.18732050e-01  8.13257992e-02  3.32449265e-02\n",
      "  4.38326932e-02 -2.49559246e-02 -3.59627269e-02  1.66319180e-02\n",
      "  5.93766849e-03 -1.43971927e-02  4.46711015e-03 -6.01986721e-02\n",
      " -5.65911569e-02 -8.21545348e-03  5.83058596e-03 -1.69482082e-02\n",
      "  9.58633889e-03  1.46733569e-02  5.05844951e-02  3.06891799e-02\n",
      "  6.60468116e-02 -2.56552286e-02 -2.78858300e-02 -3.19173336e-02\n",
      " -3.39236781e-02  1.49903325e-02 -3.03336717e-02 -6.06492022e-03\n",
      " -4.81769489e-03  1.72137320e-02 -8.23378190e-03  1.55548248e-02\n",
      "  2.69106720e-02  5.44307847e-03 -1.06898732e-02 -7.82138575e-03\n",
      " -4.44506370e-02  2.55874228e-02 -5.74760772e-02 -2.05442216e-02\n",
      " -3.07850055e-02 -1.57854892e-02 -7.07542524e-03 -4.21312265e-02\n",
      "  3.79934274e-02  6.27764612e-02 -7.67790806e-03 -3.18352990e-02\n",
      "  1.99277769e-34  1.04834503e-02 -3.39326039e-02  3.93821448e-02\n",
      "  5.53064980e-02  9.42171179e-03  1.09728212e-02 -4.91939895e-02\n",
      "  2.95023974e-02 -8.85375682e-03 -5.96248396e-02 -2.37825606e-02]\n",
      "\n",
      "Sentence: Embeddings are one of the most powerful concepts in machine learning!\n",
      "Embedding: [-2.98611429e-02 -1.37522537e-02 -4.75401767e-02  2.72126645e-02\n",
      "  3.40054147e-02  3.16465832e-02  4.26963009e-02  3.29792872e-03\n",
      "  4.35717404e-02  2.53837276e-02  3.02529484e-02  3.21131200e-02\n",
      " -3.99913192e-02  1.28760878e-02  6.70219883e-02 -7.92899877e-02\n",
      "  4.68772538e-02  2.40266304e-02 -2.07997374e-02 -1.07433060e-02\n",
      " -1.19410316e-02 -5.39290272e-02  4.21055071e-02  2.23589037e-02\n",
      " -2.98949461e-02  8.35980196e-03  1.58385374e-02 -4.80236076e-02\n",
      "  1.88435672e-03 -1.67520996e-02 -2.15628780e-02 -3.88488509e-02\n",
      "  3.06273643e-02  4.20526452e-02  1.69483428e-06 -1.86929218e-02\n",
      " -1.24558406e-02  1.32128783e-02 -4.89039496e-02  1.34746470e-02\n",
      "  2.28873547e-02  8.81780498e-03  8.64926446e-03 -2.00949311e-02\n",
      " -3.15217786e-02 -2.53433157e-02  7.57319182e-02  3.62446494e-02\n",
      "  1.25290714e-02  3.09694856e-02  4.50759660e-03 -3.50041986e-02\n",
      " -4.42552962e-04 -9.76643618e-03  6.04544990e-02  4.03472222e-02\n",
      "  1.10734608e-02  6.56205509e-03 -5.84600121e-03  3.79776349e-03\n",
      " -4.46914397e-02  1.76404957e-02  2.45915912e-02 -3.60041717e-03\n",
      "  1.02473363e-01  3.73758562e-02  6.13310421e-03 -2.24676169e-02\n",
      "  1.46482959e-02  5.00537120e-02 -2.29907744e-02  1.12925153e-02\n",
      " -3.10552903e-02 -1.49509301e-02 -2.53137341e-03  3.20944674e-02\n",
      " -4.67056334e-02 -4.85886894e-02  2.98305377e-02  6.44215718e-02\n",
      " -3.12614031e-02  3.57407331e-02  4.16527130e-02 -5.52517921e-02\n",
      " -8.74641072e-03 -2.18629669e-02 -1.12745082e-02 -2.14435980e-02\n",
      " -1.32824434e-02 -2.04866566e-02 -1.00576049e-02  3.54763307e-02\n",
      " -7.47606531e-03 -3.70188169e-02  5.77893779e-02 -2.18169093e-02\n",
      "  4.36228141e-03  2.04380769e-02  3.36815119e-02 -4.92801592e-02\n",
      "  4.82793711e-02 -1.81006000e-03 -1.05118947e-02  4.13323641e-02\n",
      " -6.79833069e-02  1.75716281e-02 -4.43412997e-02  9.90836322e-03\n",
      " -3.81810069e-02  1.10827014e-02 -5.07279076e-02 -2.17450578e-02\n",
      " -1.03836162e-02  4.60332669e-02  1.55863101e-02 -4.21366058e-02\n",
      " -2.72146501e-02  3.22818086e-02 -4.24738638e-02  2.71206982e-02\n",
      " -7.41060674e-02  4.20106985e-02  2.02437602e-02  7.31810629e-02\n",
      " -8.97690095e-03 -2.31159609e-02 -3.93559225e-02 -1.46008823e-02\n",
      " -3.30910534e-02  1.12239225e-02  2.58563133e-03 -4.36859624e-03\n",
      "  1.85855143e-02  2.69934963e-02 -1.67215634e-02  3.69569883e-02\n",
      "  4.44489829e-02 -2.21723896e-02  6.72966056e-03  1.22935446e-02\n",
      "  1.71758551e-02 -2.36471160e-03  3.72263491e-02 -2.22871136e-02\n",
      "  2.94603575e-02 -2.33691186e-02  5.38471853e-03 -3.06581482e-02\n",
      " -2.38920264e-02 -2.63613742e-02 -2.01789159e-02  1.11245625e-01\n",
      " -1.99836623e-02 -3.54029872e-02  3.84143516e-02  2.53068712e-02\n",
      "  1.99551191e-02  5.53518794e-02 -1.99332498e-02 -2.16716994e-03\n",
      "  4.91092838e-02 -4.03531305e-02 -1.16977068e-02 -5.33113480e-02\n",
      "  8.29580054e-03 -5.08251935e-02 -2.65504289e-02 -1.53242070e-02\n",
      "  5.78805758e-03  2.46570143e-03 -3.44449729e-02 -1.85131188e-03\n",
      " -3.95730212e-02 -2.71690581e-02  4.93568368e-02  8.38369504e-02\n",
      "  5.43491058e-02  8.22260752e-02  1.23894745e-02 -4.79795551e-03\n",
      "  7.77339272e-04  2.98486017e-02 -1.85584407e-02  5.98795228e-02\n",
      " -6.82796119e-03  9.78144933e-04  2.85486039e-02 -7.64620211e-03\n",
      " -1.86619591e-02 -2.69287620e-02 -2.90333107e-02 -1.37871448e-02\n",
      " -2.57602637e-03 -2.20172927e-02 -1.70821436e-02 -3.81843075e-02\n",
      "  2.21505631e-02 -3.59234288e-02 -1.19439717e-02 -3.18308212e-02\n",
      " -4.80801612e-02  9.77631845e-03 -1.04868237e-03  4.15371545e-02\n",
      " -1.10973818e-02 -4.72829901e-02  1.90984290e-02 -5.31177372e-02\n",
      "  2.11326014e-02 -2.53072148e-03  5.61055318e-02 -1.33794891e-02\n",
      " -5.95860090e-03 -1.20308697e-02  4.63929996e-02 -2.81909369e-02\n",
      "  2.25355141e-02 -2.50473293e-03 -3.52454148e-02  2.55494937e-02\n",
      "  9.10391938e-03  3.25213443e-03  2.55967001e-03 -1.25624258e-02\n",
      " -3.51496264e-02 -4.28946391e-02 -2.32327497e-03  2.41020638e-02\n",
      " -5.16838534e-03  1.68739706e-02  5.52647281e-03  2.36792732e-02\n",
      "  5.65164052e-02 -3.47868651e-02 -6.34516999e-02 -7.45629007e-03\n",
      " -1.78447496e-02  5.35898954e-02  2.67291237e-02 -8.74199197e-02\n",
      "  1.04196128e-02 -4.13906324e-04 -3.04449163e-03  9.14252549e-03\n",
      "  2.91529410e-02 -5.81832156e-02  6.83463141e-02 -4.08617817e-02\n",
      " -9.09786299e-03 -3.40769999e-02  3.52410898e-02 -1.02627808e-02\n",
      " -5.72466932e-04 -2.73456494e-03  1.59635898e-02  4.49068146e-03\n",
      " -2.09051464e-02  3.02770175e-02  2.46119257e-02 -1.44067686e-02\n",
      "  1.73269324e-02  1.99034112e-03  4.23051231e-02 -2.39176750e-02\n",
      " -3.25547606e-02 -1.45939561e-02  3.95101383e-02 -6.04649521e-02\n",
      " -3.02065350e-02  1.67189147e-02 -2.26817951e-02 -2.61954851e-02\n",
      " -5.51320165e-02  1.44908493e-02 -1.99246947e-02  3.99755174e-03\n",
      "  3.12609859e-02 -4.90727499e-02 -9.49700538e-04  5.39497100e-02\n",
      " -9.10086744e-03 -2.69486308e-02 -3.63159291e-02 -1.38436863e-02\n",
      " -4.45621945e-02  5.49359247e-02  2.17599492e-03  2.23445194e-03\n",
      " -5.23023028e-03 -1.47893922e-02  3.60591896e-02  1.45263216e-02\n",
      "  8.39191116e-03 -6.10361174e-02 -7.89947901e-03 -2.98303878e-03\n",
      "  3.56561481e-03  8.33992288e-02 -2.61215102e-02  8.06721747e-02\n",
      "  3.63054452e-03  1.69974286e-02  2.58604418e-02  1.09439483e-03\n",
      " -4.57063243e-02  5.55678867e-02  2.00643167e-02  4.76660877e-02\n",
      " -4.91053388e-02 -1.86080597e-02  3.34405489e-02 -2.57310756e-02\n",
      " -3.16369603e-03  7.21444264e-02 -1.61518864e-02 -1.33933611e-02\n",
      " -6.06294125e-02 -2.82187033e-02 -8.91921017e-03 -2.71165022e-03\n",
      "  8.04914441e-03 -4.95209955e-02  7.89434016e-02  2.76428275e-02\n",
      " -5.42577589e-03 -3.06724105e-03 -4.11826856e-02  1.39172617e-02\n",
      "  3.04253288e-02  1.02856122e-02  1.06679350e-02 -5.56554385e-02\n",
      " -1.75083261e-02  2.03868989e-02  8.43306817e-03  3.82471010e-02\n",
      " -3.89100350e-02 -1.61303300e-02  3.18059623e-02 -7.32970387e-02\n",
      " -1.76502001e-02 -4.79874015e-02 -5.55042289e-02 -5.00749331e-03\n",
      "  4.46753867e-04  3.57333682e-02 -8.24616349e-04 -3.34324650e-02\n",
      " -3.32417265e-02 -2.46460307e-02  2.15332285e-02  3.90858529e-03\n",
      "  2.53471583e-02  6.02989784e-03 -7.81613588e-03  1.23765375e-02\n",
      " -1.71039086e-02  2.68103648e-02  2.83682486e-03 -1.27643002e-02\n",
      "  1.00510925e-01  1.03581334e-02 -3.55143063e-02  1.56615861e-02\n",
      " -9.85950008e-02  4.58441339e-02 -3.15230079e-02 -2.35781837e-02\n",
      " -2.78350189e-02 -7.75709414e-05 -2.82363538e-02 -1.92918237e-02\n",
      "  1.87389217e-02  5.71941249e-02  2.56912597e-02 -3.20030265e-02\n",
      "  1.99074019e-02 -3.15819271e-02 -4.02062610e-02  5.77630661e-02\n",
      "  1.72974244e-02 -5.37012815e-02 -1.25325695e-02 -1.45483706e-02\n",
      " -5.76174185e-02  1.09727718e-02 -2.04728413e-02  2.85540372e-02\n",
      " -5.04399948e-02  4.36991118e-02  1.75710749e-02 -1.02343559e-02\n",
      " -9.69772339e-02 -2.99996510e-02 -2.86679436e-02  2.24936716e-02\n",
      " -1.68121196e-02 -1.43673699e-02 -8.79587419e-03 -1.69044193e-02\n",
      "  2.41557620e-02 -6.53192475e-02 -4.10800427e-02 -2.34056897e-02\n",
      " -6.76065013e-02 -1.55690545e-02  3.62358242e-02  7.83160180e-02\n",
      " -4.97516617e-02 -7.08547384e-02 -5.01179770e-02 -8.56427476e-04\n",
      "  5.44901425e-03  4.34703566e-03  9.88052711e-02 -2.16415748e-02\n",
      " -1.87751073e-02  1.15069542e-02  2.63996236e-02  1.65235605e-02\n",
      " -2.24057324e-02 -4.31826524e-02  1.31803870e-01 -2.97034718e-02\n",
      "  2.65935045e-02 -1.38888787e-02 -1.67003646e-02  3.44145149e-02\n",
      " -8.94355774e-03  6.16001301e-02 -3.42303216e-02  2.46424484e-03\n",
      " -8.14093091e-03  5.80325164e-02  5.24208471e-02 -1.53281800e-02\n",
      "  4.01382744e-02  1.51406806e-02 -3.01467348e-03 -4.97021303e-02\n",
      " -4.24307492e-03  5.77288531e-02  3.17873657e-02  4.74008396e-02\n",
      "  2.95218434e-02 -1.50122140e-02 -2.47944519e-02 -7.11501613e-02\n",
      "  2.06847731e-02  3.11488397e-02 -5.86067839e-03  1.62786338e-02\n",
      " -3.93683277e-02  5.46506532e-02  3.26595381e-02 -1.87021475e-02\n",
      " -9.79863033e-02  4.33768332e-03 -5.58157004e-02 -1.34621151e-02\n",
      "  2.88454201e-02  1.58748366e-02 -3.32564153e-02  1.44413277e-03\n",
      " -5.51108271e-02  8.24673474e-02  2.38845646e-02 -2.04838514e-02\n",
      " -4.78585716e-03  3.78722586e-02 -4.87563275e-02  3.44647206e-02\n",
      "  1.10358587e-02  1.12449918e-02  1.33263487e-02 -3.46375667e-02\n",
      " -6.92220479e-02  7.30115082e-03 -6.57011662e-03  1.73204392e-02\n",
      "  5.23061305e-03  4.48132567e-02  3.89853343e-02 -1.99275240e-02\n",
      " -1.80920698e-02  3.25937755e-02 -2.02027038e-02  4.86247707e-04\n",
      " -8.88761971e-03 -1.91347916e-02  2.50686184e-02  4.74019162e-02\n",
      "  2.18657590e-03 -1.69987939e-02  3.62670794e-02  3.46247293e-03\n",
      "  4.21927823e-03  8.04170966e-02  3.10627595e-02 -1.04945642e-03\n",
      " -3.55466381e-02  4.34837341e-02 -3.06218304e-02 -3.03192325e-02\n",
      " -4.13175821e-02 -1.05258515e-02 -2.35242043e-02 -1.86771657e-02\n",
      "  4.42931056e-03  5.45056164e-02 -6.05017692e-02  2.48421766e-02\n",
      " -3.36967669e-02 -4.54169251e-02 -2.63173170e-02  6.98054815e-03\n",
      "  6.92871213e-02 -2.04491410e-02 -1.96813233e-02 -9.72561352e-03\n",
      " -1.21564409e-02  7.89339654e-03  1.84750592e-03 -6.93650767e-02\n",
      "  2.43358072e-02  4.00609560e-02  3.44013236e-02 -2.84281634e-02\n",
      " -1.09431557e-02  1.38742710e-02 -4.40590875e-03  1.19350327e-03\n",
      " -8.81165564e-02  1.15931015e-02 -2.56350450e-02  5.57525456e-02\n",
      "  1.26946136e-01  5.39565906e-02 -1.41436812e-02  1.27196591e-02\n",
      " -1.32235838e-02 -5.94484322e-02  2.86704246e-02  2.57285107e-02\n",
      " -8.33769329e-03  8.17378284e-04  5.93053782e-03  3.29111032e-02\n",
      "  4.12751958e-02 -5.77961886e-03 -1.71124525e-02  1.06227333e-02\n",
      " -2.19601709e-02 -4.97207008e-02  2.53765807e-02 -5.60257726e-33\n",
      " -1.35397157e-02 -3.77958529e-02 -2.67922878e-03 -3.69652407e-04\n",
      " -1.98267289e-02  5.47051383e-03  6.02688035e-03  1.93068795e-02\n",
      "  3.87973548e-03  2.97698714e-02 -1.88229028e-02  2.20038509e-03\n",
      "  8.17020051e-03  1.61965284e-02  3.17529365e-02 -6.83412887e-03\n",
      "  2.19252463e-02  4.37701674e-04  2.96859182e-02 -2.62557399e-02\n",
      "  6.49384549e-03  3.56025398e-02  1.58608588e-03 -4.76583913e-02\n",
      " -5.26238531e-02  3.78274061e-02  3.54342535e-02 -3.10347639e-02\n",
      "  7.96404947e-03  5.48469387e-02 -3.56443599e-02  9.10136476e-03\n",
      " -9.45984758e-03 -4.63287458e-02 -1.63907204e-02  6.32452890e-02\n",
      " -1.38588538e-02 -5.95724955e-02 -1.57990456e-02  2.01887153e-02\n",
      " -1.98292285e-02 -3.49211581e-02  2.27937698e-02 -5.91621846e-02\n",
      "  4.18854617e-02  1.20738824e-03  5.19158579e-02 -1.88436266e-02\n",
      " -3.12102251e-02  2.34932136e-02 -7.41029158e-02 -2.76590377e-04\n",
      " -1.51720140e-02  6.11713491e-02  1.25065118e-01 -1.28459064e-02\n",
      " -1.12671554e-02  1.51760050e-03 -8.09153542e-02  1.12689575e-02\n",
      " -1.97573584e-02  2.74268258e-02  9.40998830e-03 -9.58755333e-03\n",
      "  2.54850443e-02  6.81659132e-02 -1.83453467e-02 -1.00963980e-01\n",
      " -9.45247896e-03 -5.27007319e-03  1.98683981e-02  9.80848372e-02\n",
      "  3.15633267e-02  5.30422628e-02  3.75123583e-02 -6.64209202e-02\n",
      " -5.92879988e-02 -1.57074351e-02  1.76609531e-02 -5.81073500e-02\n",
      "  2.23230720e-02  1.29869329e-02 -3.30261067e-02  9.96951479e-04\n",
      " -9.87092033e-03 -3.12955305e-02  2.28525023e-03 -4.91250493e-02\n",
      "  1.47694228e-02 -1.83367599e-02 -4.16306518e-02  3.76896933e-02\n",
      "  3.35410275e-02 -7.97111690e-02  4.01299670e-02  1.59071963e-02\n",
      "  5.06086834e-03  4.28808369e-02  2.29760278e-02 -4.13350835e-02\n",
      " -3.10502984e-02 -5.26404381e-02 -4.95404527e-02 -2.94256806e-02\n",
      "  5.94924614e-02 -2.59802733e-02  3.02497204e-02  8.80402979e-03\n",
      " -4.84466851e-02 -2.00851150e-02  9.82183218e-03 -7.89193660e-02\n",
      "  4.52871807e-03 -9.34896711e-03  9.23311524e-03 -3.17361876e-02\n",
      "  2.10833177e-02  6.37125690e-03  3.36347893e-02  3.83613631e-02\n",
      " -4.55527864e-02  1.08126178e-03 -9.83322412e-03  7.70194782e-03\n",
      " -2.87617911e-02 -1.74959823e-02 -4.27817088e-03  2.81287134e-02\n",
      "  4.97339591e-02 -7.45570213e-02 -1.07008992e-02 -7.66044995e-03\n",
      "  2.33968919e-07  1.52483461e-02  8.39613825e-02  3.67242806e-02\n",
      " -3.69249061e-02  3.64752077e-02  4.26422022e-02 -4.39831475e-03\n",
      "  1.78133808e-02 -2.67076232e-02 -7.13904342e-03  5.59975281e-02\n",
      "  3.13966535e-02  2.13436899e-03  3.90371345e-02 -8.78527984e-02\n",
      " -2.21659876e-02 -2.47735288e-02 -1.18189622e-02 -7.89705478e-03\n",
      " -2.08857823e-02  4.30555977e-02  1.07643597e-01  4.40617949e-02\n",
      "  1.47962719e-02  2.44862698e-02 -3.86268310e-02  1.80743076e-02\n",
      " -1.47839938e-03  7.74166733e-02 -4.19565775e-02 -3.80529352e-02\n",
      "  3.61256711e-02  1.59032585e-03  1.95324030e-02 -2.00080462e-02\n",
      "  4.22537960e-02  3.06110885e-02 -3.53686465e-03  5.93100162e-03\n",
      " -2.23223735e-02 -2.07131393e-02 -3.62908887e-03  1.74653586e-02\n",
      " -4.08758968e-02  5.91595173e-02 -5.89099452e-02 -3.96753959e-02\n",
      " -3.33529301e-02  1.02161057e-02  6.97292387e-03  7.70389736e-02\n",
      " -1.86911505e-02 -1.82568263e-02 -2.42319200e-02 -3.40699288e-03\n",
      " -3.60554680e-02  4.33389135e-02 -3.48602571e-02  5.27769066e-02\n",
      "  2.89709363e-02 -4.98462431e-02 -1.94749199e-02  1.16398521e-02\n",
      " -3.04615460e-02  8.04637894e-02  6.56248480e-02 -2.84533482e-02\n",
      "  1.81615301e-34 -4.19158954e-03 -2.57882662e-02  5.17320037e-02\n",
      "  4.94420417e-02  1.32475980e-02 -4.21994887e-02 -1.12458598e-02\n",
      " -2.61519253e-02  5.51130474e-02  2.20024381e-02 -2.51170434e-02]\n",
      "\n",
      "Sentence: Learn to use embeddings well and you'll be well on your way to being an AI engineer.\n",
      "Embedding: [-2.20730547e-02  2.08950844e-02 -6.03005029e-02  8.43949430e-03\n",
      "  4.37650867e-02  1.55070238e-02  4.99907956e-02 -3.03232670e-02\n",
      "  4.94783968e-02  2.35512573e-02  3.29350270e-02  1.53878108e-02\n",
      " -6.68355003e-02  1.11002855e-01  6.92677274e-02 -2.31888033e-02\n",
      "  3.79102528e-02 -4.94144717e-03 -1.57800969e-02 -3.45476530e-02\n",
      " -2.65053045e-02 -2.47879811e-02 -1.86141673e-02  3.00361905e-02\n",
      " -2.81185675e-02 -8.75127688e-03 -3.30773811e-03 -2.06115581e-02\n",
      "  1.03315748e-02 -1.51483342e-02 -3.48331034e-02 -2.63247769e-02\n",
      "  2.06907913e-02  3.79108898e-02  1.81912947e-06 -2.44284840e-03\n",
      " -1.80560315e-03  5.61761856e-03 -2.79870015e-02  1.54703567e-02\n",
      "  3.06456313e-02  3.72600704e-02 -1.55611672e-02  2.54414622e-02\n",
      " -6.42072633e-02  3.16353478e-02  6.63442239e-02  3.80970016e-02\n",
      "  5.57844639e-02  5.31659126e-02 -9.69289336e-03 -3.61423716e-02\n",
      "  3.72434594e-02 -4.67832480e-03  5.14575429e-02  1.00058615e-02\n",
      "  4.90287133e-03  1.41562326e-02  4.95100170e-02  3.32953339e-03\n",
      " -3.21100950e-02  4.42387983e-02  3.27416398e-02 -7.90620316e-03\n",
      "  1.07809782e-01  7.32945353e-02  3.36702913e-02 -4.28345427e-02\n",
      "  1.05966423e-02  2.05654018e-02 -2.02669837e-02  1.04964050e-02\n",
      " -1.97615996e-02 -2.89532873e-05 -2.61862315e-02 -1.85173769e-02\n",
      " -3.44269760e-02 -4.08621915e-02  2.32571419e-02  2.14196015e-02\n",
      "  1.31320357e-02 -3.27211805e-02 -1.91425551e-02 -2.86572408e-02\n",
      " -1.16858557e-02  1.21910665e-02  1.05248066e-02 -3.39584760e-02\n",
      "  3.08902003e-03 -4.44888175e-02  2.65105441e-02  1.09535968e-02\n",
      "  2.51450632e-02 -6.48842938e-03  4.54374589e-03 -2.02785134e-02\n",
      " -1.03216842e-02  2.06590313e-02 -1.65313799e-02 -2.45611388e-02\n",
      "  5.47549278e-02  2.68261321e-02  2.95511149e-02  3.86754572e-02\n",
      " -7.76720569e-02  3.80055495e-02 -2.98364796e-02  7.96886310e-02\n",
      " -3.00943162e-02  7.57849030e-03 -6.89827055e-02 -2.92666890e-02\n",
      " -2.35579181e-02  3.48197930e-02  2.52938457e-02 -4.53817844e-02\n",
      " -1.57938469e-02  4.39030901e-02 -4.04335596e-02  8.32536537e-03\n",
      " -2.84665748e-02  4.94934358e-02  2.41276305e-02  3.02191880e-02\n",
      " -4.99590300e-02 -5.94533272e-02 -3.70175615e-02  1.30331218e-02\n",
      " -3.36468481e-02  3.45589742e-02 -1.44523820e-02  2.57639643e-02\n",
      "  4.61184932e-03  2.21552104e-02 -4.93463036e-03  9.66005251e-02\n",
      " -2.72455276e-03  5.65320021e-04 -3.24247591e-02  1.31681748e-02\n",
      "  4.41607460e-02 -7.03044422e-03  6.84261248e-02 -2.28166077e-02\n",
      " -2.81032384e-03 -4.23882864e-02 -1.33632226e-02 -5.96738532e-02\n",
      " -6.96122879e-03 -2.31901519e-02 -3.78851742e-02  9.80186835e-02\n",
      " -2.21729353e-02 -2.30062436e-02  3.22815143e-02  8.21806025e-03\n",
      " -7.04126433e-03  4.84078974e-02  4.23291102e-02 -2.59717461e-03\n",
      "  1.20455879e-04  1.67414248e-02  2.91197933e-02 -1.28740892e-02\n",
      " -2.41077635e-02 -3.29319239e-02 -3.50289093e-03 -3.19322348e-02\n",
      " -2.64171809e-02  2.30404865e-02  1.11636873e-02 -9.96009633e-03\n",
      " -1.75901093e-02 -2.00277683e-03  1.21595114e-02  4.67822999e-02\n",
      "  5.20881861e-02  7.21171945e-02  1.94979012e-02  1.15071982e-02\n",
      "  5.94169926e-03 -1.47833107e-02 -2.87724398e-02  6.72666058e-02\n",
      " -1.68758929e-02  5.25872782e-03 -3.39737087e-02  5.24596535e-02\n",
      " -2.59793364e-02 -4.41379920e-02  1.47454231e-03 -1.06599517e-02\n",
      " -1.51859373e-02 -1.55867159e-03  1.81505606e-02 -4.85411175e-02\n",
      "  3.67919146e-03 -6.59312904e-02 -1.49418106e-02 -3.23528759e-02\n",
      " -2.79949866e-02  1.71856824e-02 -7.87094701e-03  4.65692058e-02\n",
      "  1.47123709e-02 -7.40438998e-02 -6.52104393e-02 -5.22735305e-02\n",
      " -1.82342846e-02  5.20858839e-02  3.06305103e-02 -2.36037038e-02\n",
      "  2.42385007e-02 -1.83938723e-02 -4.83019883e-03 -2.13387031e-02\n",
      "  1.56583618e-02  9.87338927e-03 -4.25561033e-02  6.00465015e-03\n",
      " -3.14498297e-03  4.51508630e-03 -1.52780465e-03  1.13731902e-02\n",
      " -6.96354657e-02 -3.37257199e-02  1.33407079e-02  4.87288414e-03\n",
      " -7.81492796e-03  4.78049517e-02 -1.59711782e-02  3.14606167e-02\n",
      "  5.15920669e-02 -4.05123010e-02 -5.06460704e-02  9.99929011e-03\n",
      " -2.00729556e-02  4.21552733e-02  3.03181689e-02 -1.00431271e-01\n",
      " -4.12019603e-02  3.43990028e-02  3.29208709e-02  1.07413437e-03\n",
      "  3.70961502e-02 -6.94237277e-02  6.52394816e-02  8.31672177e-03\n",
      "  1.68036688e-02 -2.60705557e-02  8.14490765e-03 -1.48009723e-02\n",
      " -2.65671667e-02  3.29321437e-02 -7.37515697e-03  7.23974593e-03\n",
      " -2.69329119e-02  1.71754230e-02 -2.28083115e-02 -4.75346344e-03\n",
      "  2.88569089e-02  1.30798158e-04  5.44128232e-02 -1.43379075e-02\n",
      "  1.89891476e-02 -1.32732010e-02  4.01177369e-02 -7.29275495e-02\n",
      " -2.41211243e-02  3.16216908e-02 -1.68015286e-02  8.47542100e-03\n",
      " -5.23940548e-02 -1.43882846e-02 -1.46156624e-02  6.39906898e-03\n",
      "  2.15113945e-02 -5.18960617e-02 -4.30576317e-02  2.34076027e-02\n",
      "  2.30270461e-03 -2.48434003e-02 -4.38243411e-02 -2.16570962e-02\n",
      " -6.91594929e-02  1.76770128e-02  2.12068260e-02 -2.20293142e-02\n",
      " -1.06773861e-02  9.57431272e-03  2.21988391e-02  5.51470704e-02\n",
      "  1.03682717e-02 -8.14825669e-02 -7.94703420e-03 -1.85866095e-02\n",
      "  1.20494105e-02  7.51404017e-02 -1.41215846e-02  8.83924291e-02\n",
      "  3.12628597e-02  8.12266581e-03 -2.29444932e-02  3.96010280e-02\n",
      " -2.00167857e-02  9.16027352e-02 -2.06839088e-02  5.84990792e-02\n",
      " -4.32367995e-02 -4.74755187e-03 -9.51895211e-03  5.42950118e-03\n",
      "  1.19139477e-04  6.15377724e-02 -1.68787211e-03 -4.66321334e-02\n",
      " -2.01405082e-02  1.32406447e-02  9.70687438e-03  2.73846928e-02\n",
      "  3.06639578e-02  6.71574147e-03  8.71220902e-02 -1.97374448e-03\n",
      "  8.18298385e-03  5.44372713e-03 -5.76205328e-02  1.34821851e-02\n",
      "  5.06276172e-03 -2.10568551e-02  1.25937117e-02 -5.49773499e-03\n",
      " -1.44645311e-02 -2.92567462e-02  5.53299226e-02 -2.60099489e-02\n",
      " -2.82455026e-03 -2.30902936e-02  8.89708661e-03 -2.61565186e-02\n",
      "  9.08598828e-04 -6.16204366e-02 -7.56419078e-02 -1.05932429e-02\n",
      " -1.19564068e-02  6.71458617e-02 -1.96235310e-02 -5.00934124e-02\n",
      " -3.91229168e-02 -3.07008997e-02  7.18906745e-02  9.29247681e-03\n",
      " -6.34389650e-03  7.86940043e-04 -1.36484122e-02  2.87188403e-02\n",
      "  4.01224419e-02  1.28037157e-02  1.77381057e-02 -4.75975731e-03\n",
      "  5.47173359e-02  1.10809226e-03 -2.25790311e-02 -2.80295988e-03\n",
      " -1.13696113e-01  2.55904663e-02  4.00385674e-04 -4.39810120e-02\n",
      "  1.36318589e-02 -1.54137518e-02 -4.99015227e-02 -2.32889764e-02\n",
      " -1.62987504e-03  3.95834967e-02  1.89040545e-02 -3.02702505e-02\n",
      "  2.71437895e-02  1.05689804e-03 -4.21067737e-02  3.71961072e-02\n",
      "  3.54257561e-02 -6.98274076e-02 -2.20937897e-02 -4.01495099e-02\n",
      " -1.90164018e-02 -2.69834902e-02 -1.51212616e-02  3.33365425e-02\n",
      " -9.74889845e-02  1.73102058e-02  6.21015253e-03 -2.59420183e-03\n",
      " -1.10152967e-01 -6.10185787e-02 -1.36549594e-02 -1.35034602e-02\n",
      " -6.72575012e-02 -4.05119732e-03 -6.64985552e-03  3.86573584e-03\n",
      "  9.43472143e-03 -3.86637673e-02 -1.93593837e-02  1.34934094e-02\n",
      " -4.58106697e-02  6.06737360e-02  6.06380440e-02  4.85596061e-02\n",
      " -4.56088483e-02 -5.71936667e-02 -1.55094927e-02  3.40963453e-02\n",
      "  9.48140048e-04 -9.94352531e-03  2.84658410e-02 -3.29024270e-02\n",
      " -2.83211395e-02  3.19907889e-02  2.61299480e-02 -2.74054632e-02\n",
      " -1.36353113e-02  7.47714937e-03  1.19430237e-01 -4.45807353e-02\n",
      "  1.07672736e-02 -8.69423896e-02 -2.19551641e-02  1.83874592e-02\n",
      " -1.06521631e-02 -1.89242903e-02 -3.06514278e-02 -3.04702204e-02\n",
      " -3.22214775e-02  4.12150435e-02  8.95760860e-03 -2.73179375e-02\n",
      "  9.39998124e-03 -9.57122771e-04 -1.94010567e-02 -4.92622554e-02\n",
      " -9.18891001e-03  4.66894135e-02  5.41892983e-02  2.21609324e-02\n",
      " -2.86351684e-02  5.20295165e-02  2.47590300e-02 -7.14267939e-02\n",
      " -1.26207424e-02  7.35521503e-03  2.13784985e-02  2.93513797e-02\n",
      " -2.57650558e-02  5.20562232e-02 -2.74892189e-02 -3.10242344e-02\n",
      " -9.02881101e-02  6.10371828e-02 -5.22610284e-02  2.13110968e-02\n",
      "  4.41735908e-02  3.23370695e-02  1.75648164e-02 -2.39519626e-02\n",
      " -2.69709174e-02  5.11278994e-02  2.69064456e-02 -4.51932475e-02\n",
      "  2.52652774e-03  2.44934354e-02 -2.89540663e-02  2.79992726e-02\n",
      " -1.36022484e-02 -4.32368144e-02  1.85829978e-02  7.63842181e-05\n",
      "  2.43503624e-03 -3.73323658e-03 -1.72280092e-02  1.01292403e-02\n",
      "  1.98436920e-02 -2.60017663e-02 -3.40174953e-03  1.09126391e-02\n",
      " -4.16363142e-02  3.37032080e-02 -2.81634722e-02  1.79126319e-02\n",
      " -4.53095250e-02 -1.09818606e-02 -2.20831297e-03  1.99102275e-02\n",
      "  3.56372111e-02 -3.11799180e-02  3.78752798e-02 -1.41408388e-02\n",
      " -2.16907784e-02  2.73019373e-02  3.69812781e-03  6.35386705e-02\n",
      "  1.22669684e-02 -6.02268334e-03 -7.60754058e-03 -1.86565686e-02\n",
      " -5.64713823e-03 -2.20050965e-03 -1.31825330e-02  1.67724062e-02\n",
      " -3.77264656e-02  2.97896210e-02 -5.01569249e-02  4.89088707e-02\n",
      " -6.07444905e-02 -8.39419216e-02 -5.09001091e-02  1.81768481e-02\n",
      "  6.66732267e-02 -3.30037740e-03 -2.82404572e-03 -5.35405874e-02\n",
      "  3.90340909e-02  2.19851807e-02  3.13554928e-02 -3.36527266e-02\n",
      "  1.96914244e-02  1.67883802e-02  5.04002832e-02  3.08061205e-03\n",
      " -7.24796322e-04  4.42907512e-02 -4.12958069e-03  4.29329164e-02\n",
      " -6.62552863e-02  1.16061699e-03 -2.81716529e-02  1.56886168e-02\n",
      "  9.78134051e-02  5.53594232e-02 -1.39379054e-02  2.12306883e-02\n",
      " -1.30955437e-02 -6.82027712e-02 -8.09108431e-04  4.99291308e-02\n",
      " -2.69266162e-02 -2.97804344e-02  3.84461805e-02  1.97354835e-02\n",
      "  3.37088332e-02  1.65874064e-02  5.77317178e-03 -3.04898228e-02\n",
      " -1.52511718e-02 -3.56159210e-02 -8.69221054e-03 -5.42296980e-33\n",
      "  3.24372924e-03 -3.46329734e-02  3.58932316e-02  1.83770694e-02\n",
      " -2.17505284e-02 -3.26411948e-02  2.88397912e-03  1.50463376e-02\n",
      " -1.75269553e-03 -1.99418552e-02 -6.10355567e-03  2.23846976e-02\n",
      " -8.78949184e-04  2.48684827e-02  3.39737199e-02  2.75592934e-02\n",
      "  3.37792598e-02  3.98564860e-02  2.55544912e-02  1.83042847e-02\n",
      " -2.92878747e-02  5.18079428e-03  8.37678439e-04 -3.66559774e-02\n",
      " -3.46733369e-02  3.82687338e-02  5.50825521e-03 -4.35188338e-02\n",
      "  2.44077351e-02  3.54167409e-02 -2.13442165e-02  2.86623873e-02\n",
      " -2.65391544e-04  3.73409726e-02 -8.68167635e-03  3.04786721e-03\n",
      " -2.71681882e-02 -3.85087952e-02 -6.12389669e-02 -2.00847792e-03\n",
      " -1.22079821e-02 -8.67197663e-02  3.75359086e-03 -1.77707579e-02\n",
      "  8.32476281e-03 -1.69168171e-02  7.02404007e-02  3.32233869e-02\n",
      "  4.34312895e-02  1.47017008e-02 -1.25546902e-01  1.50866490e-02\n",
      " -5.43164201e-02 -1.79156906e-03  4.99600805e-02 -1.53785814e-02\n",
      "  3.32683735e-02 -3.07708848e-02 -1.83896646e-02  9.45796352e-03\n",
      " -4.60290723e-02 -2.03866931e-03  2.62428690e-02 -5.00789322e-02\n",
      "  2.01835893e-02  6.08982742e-02 -2.01180596e-02 -2.60054879e-02\n",
      "  1.05925500e-02 -3.31153758e-02  1.62595753e-02  7.77862072e-02\n",
      " -1.90726097e-03 -5.62890386e-03  1.43715953e-02 -4.06833626e-02\n",
      " -5.14971018e-02  1.66213111e-04 -3.33068590e-03  1.44689912e-02\n",
      "  4.24915081e-04  3.04453131e-02 -1.83636677e-02  1.51183724e-03\n",
      "  2.99861878e-02 -3.68001647e-02  8.35629646e-03 -3.31025012e-02\n",
      "  2.66912226e-02  5.47832018e-03 -1.80525109e-02  2.42576785e-02\n",
      "  5.72706806e-03 -5.93372174e-02  1.04358509e-01 -9.87922680e-03\n",
      " -1.36106033e-02  5.79998642e-02  2.50108372e-02  2.89336909e-02\n",
      " -3.20522487e-02 -3.40232886e-02 -3.41698788e-02 -2.76980978e-02\n",
      "  6.47003055e-02  1.50797674e-02 -1.61925405e-02  3.03265732e-02\n",
      " -2.67188158e-02 -3.67773920e-02 -2.27845591e-02 -5.36433347e-02\n",
      "  1.90500394e-02 -3.42503563e-02  1.32688815e-02 -5.41325193e-03\n",
      "  7.49740377e-03 -7.37037801e-04 -3.08569558e-02  3.82287689e-02\n",
      " -2.08311900e-02 -3.43154892e-02  5.60237328e-03  1.44999940e-02\n",
      " -3.76364030e-02 -5.11782058e-02 -3.51075381e-02  1.71867963e-02\n",
      "  1.50721688e-02 -9.62025896e-02 -1.53545542e-02  1.58375893e-02\n",
      "  2.42941042e-07 -5.88813331e-03  7.68795311e-02  5.86063452e-02\n",
      "  2.21232902e-02 -2.36690361e-02  5.25274873e-02  1.48660913e-02\n",
      "  7.34178722e-03 -4.98912809e-03  4.37413678e-02 -1.28331603e-02\n",
      "  3.37342322e-02 -1.10813929e-02 -1.33937774e-02 -7.80063719e-02\n",
      " -1.36330593e-02  1.94749273e-02  1.91754184e-03 -3.00251823e-02\n",
      "  1.02605642e-04  9.54534188e-02  1.19653895e-01  3.73371467e-02\n",
      "  4.25128080e-03  2.05130149e-02 -3.85415331e-02 -1.90614238e-02\n",
      "  5.88793531e-02  6.81264922e-02 -3.12596038e-02 -6.50440902e-02\n",
      "  2.48045567e-02  3.90002417e-04  7.54762441e-02 -3.46076526e-02\n",
      "  1.32949213e-02  4.14005630e-02  3.07568777e-02  5.50353341e-03\n",
      " -1.53084286e-03  2.75993180e-02  6.46033091e-03  1.05398316e-02\n",
      " -3.09298690e-02  4.60232869e-02 -3.64922099e-02 -1.39540350e-02\n",
      " -3.53720523e-02  7.97885412e-04  1.40632801e-02  1.80259235e-02\n",
      " -1.43368198e-02  2.19208188e-03 -3.96873914e-02 -1.17281917e-02\n",
      " -4.45220321e-02  8.05765111e-03 -4.04861383e-02  3.56149375e-02\n",
      "  5.12852408e-02 -6.64039403e-02 -5.32594845e-02  8.92902724e-03\n",
      "  1.56424902e-02  1.02110855e-01  8.10775254e-03 -4.03859606e-03\n",
      "  2.02352582e-34 -1.38294557e-02 -1.17623564e-02  1.51006728e-02\n",
      "  8.25895891e-02  2.39227936e-02 -1.10377725e-02  3.65657965e-03\n",
      " -7.44783645e-03  2.94555388e-02  3.52993980e-03 -6.10421300e-02]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "embedding_model = SentenceTransformer(model_name_or_path = \"all-mpnet-base-v2\",\n",
    "                                      device=\"mps\")\n",
    "\n",
    "# Create a list of sentences to turn into numbers\n",
    "sentences = [\n",
    "    \"The Sentences Transformers library provides an easy and open-source way to create embeddings.\",\n",
    "    \"Sentences can be embedded one by one or as a list of strings.\",\n",
    "    \"Embeddings are one of the most powerful concepts in machine learning!\",\n",
    "    \"Learn to use embeddings well and you'll be well on your way to being an AI engineer.\"\n",
    "]\n",
    "\n",
    "\n",
    "# Sentences are encoded/embedded by calling model.encode()\n",
    "embeddings = embedding_model.encode(sentences)\n",
    "embeddings_dict = dict(zip(sentences, embeddings))\n",
    "\n",
    "# See the embeddings\n",
    "for sentence, embedding in embeddings_dict.items():\n",
    "    print(\"Sentence:\", sentence)\n",
    "    print(\"Embedding:\", embedding)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = embedding_model.encode(\"My favourite animal is the cow\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 384, 'do_lower_case': False}) with Transformer model: MPNetModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model.to(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1680/1680 [01:36<00:00, 17.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12min 27s, sys: 4min 27s, total: 16min 54s\n",
      "Wall time: 1min 36s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for item in tqdm(pages_and_chunks_over_min_token_len):\n",
    "    item[\"embedding\"]=embedding_model.encode(item[\"sentence_chunk\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.47 ms, sys: 24 μs, total: 1.49 ms\n",
      "Wall time: 1.51 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'often. • Calm your “sweet tooth” by eating fruits, such as berries or an apple. • Replace sugary soft drinks with seltzer water, tea, or a small amount of 100 percent fruit juice added to water or soda water. The Food Industry: Functional Attributes of Carbohydrates and the Use of Sugar Substitutes In the food industry, both fast-releasing and slow-releasing carbohydrates are utilized to give foods a wide spectrum of functional attributes, including increased sweetness, viscosity, bulk, coating ability, solubility, consistency, texture, body, and browning capacity. The differences in chemical structure between the different carbohydrates confer their varied functional uses in foods. Starches, gums, and pectins are used as thickening agents in making jam, cakes, cookies, noodles, canned products, imitation cheeses, and a variety of other foods. Molecular gastronomists use slow- releasing carbohydrates, such as alginate, to give shape and texture to their fascinating food creations. Adding fiber to foods increases bulk. Simple sugars are used not only for adding sweetness, but also to add texture, consistency, and browning. In ice cream, the combination of sucrose and corn syrup imparts sweetness as well as a glossy appearance and smooth texture.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "text_chunks = [item[\"sentence_chunk\"] for item in pages_and_chunks_over_min_token_len]\n",
    "text_chunks[419]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 33s, sys: 30.5 s, total: 2min 4s\n",
      "Wall time: 37.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.06742427,  0.09022824, -0.00509553, ..., -0.02211548,\n",
       "        -0.02321365,  0.01256903],\n",
       "       [ 0.0552156 ,  0.05921397, -0.01661672, ..., -0.01204062,\n",
       "        -0.01028468,  0.02273966],\n",
       "       [ 0.02798016,  0.03398141, -0.02064266, ..., -0.00536188,\n",
       "         0.02125601,  0.03130551],\n",
       "       ...,\n",
       "       [ 0.07705151,  0.00978557, -0.01218173, ..., -0.04086807,\n",
       "        -0.07517633, -0.02405261],\n",
       "       [ 0.10304512, -0.01647023,  0.00826849, ..., -0.05742176,\n",
       "        -0.02828031, -0.02946864],\n",
       "       [ 0.08637734, -0.0125359 , -0.01127469, ..., -0.05223794,\n",
       "        -0.03367294, -0.02986607]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "#Embed all texts into batches\n",
    "text_chunk_embedding  = embedding_model.encode(text_chunks , \n",
    "                                               batch_size =32 ,\n",
    "                                               convert_to_tensors= True)\n",
    "\n",
    "text_chunk_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save embeddings to file\n",
    "\n",
    "Since creating embeddings can be a timely process (not so much for our case but it can be for more larger datasets), let's turn our `pages_and_chunks_over_min_token_len` list of dictionaries into a DataFrame and save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save embeddings to file\n",
    "text_chunks_and_embeddings_df = pd.DataFrame(pages_and_chunks_over_min_token_len)\n",
    "embeddings_df_save_path = \"text_chunks_and_embeddings_df.csv\"\n",
    "text_chunks_and_embeddings_df.to_csv(embeddings_df_save_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunking and embedding questions\n",
    "\n",
    "> **Which embedding model should I use?**\n",
    "\n",
    "This depends on many factors. My best advice is to experiment, experiment, experiment! \n",
    "\n",
    "If you want the model to run locally, you'll have to make sure it's feasible to run on your own hardware. \n",
    "\n",
    "A good place to see how different models perform on a wide range of embedding tasks is the [Hugging Face Massive Text Embedding Benchmark (MTEB) Leaderboard](https://huggingface.co/spaces/mteb/leaderboard).\n",
    "\n",
    "> **What other forms of text chunking/splitting are there?**\n",
    "\n",
    "There are a fair few options here too. We've kept it simple with groups of sentences.\n",
    "\n",
    "For more, [Pinecone has a great guide on different kinds of chunking](https://www.pinecone.io/learn/chunking-strategies/) including for different kinds of data such as markdown and LaTeX.\n",
    "\n",
    "Libraries such as [LangChain also have a good amount of in-built text splitting options](https://python.langchain.com/docs/modules/data_connection/document_transformers/).\n",
    "\n",
    "> **What should I think about when creating my embeddings?**\n",
    "\n",
    "Our model turns text inputs up to 384 tokens long in embedding vectors of size 768.\n",
    "\n",
    "Generally, the larger the vector size, the more information that gets encoded into the embedding (however, this is not always the case, as smaller, better models can outperform larger ones).\n",
    "\n",
    "Though with larger vector sizes comes larger storage and compute requirements.\n",
    "\n",
    "Our model is also relatively small (420MB) in size compared to larger models that are available.\n",
    "\n",
    "Larger models may result in better performance but will also require more compute.\n",
    "\n",
    "So some things to think about:\n",
    "* Size of input - If you need to embed longer sequences, choose a model with a larger input capacity.\n",
    "* Size of embedding vector - Larger is generally a better representation but requires more compute/storage.\n",
    "* Size of model - Larger models generally result in better embeddings but require more compute power/time to run.\n",
    "* Open or closed - Open models allow you to run them on your own hardware whereas closed models can be easier to setup but require an API call to get embeddings.\n",
    "\n",
    "> **Where should I store my embeddings?**\n",
    "\n",
    "If you've got a relatively small dataset, for example, under 100,000 examples (this number is rough and only based on first hand experience), `np.array` or `torch.tensor` can work just fine as your dataset.\n",
    "\n",
    "But if you've got a production system and want to work with 100,000+ embeddings, you may want to look into a [vector database]( https://en.wikipedia.org/wiki/Vector_database) (these have become very popular lately and there are many offerings).\n",
    "\n",
    "### Document Ingestion and Embedding Creation Extensions\n",
    "\n",
    "One major extension to the workflow above would to functionize it.\n",
    "\n",
    "Or turn it into a script.\n",
    "\n",
    "As in, take all the functionality we've created and package it into a single process (e.g. go from document -> embeddings file).\n",
    "\n",
    "So you could input a document on one end and have embeddings come out the other end. The hardest part of this is knowing what kind of preprocessing your text may need before it's turned into embeddings. Cleaner text generally means better results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
